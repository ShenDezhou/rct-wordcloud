第 42 卷

计

2019 论文在线出版号 No.34

算

机

学

Vol. 42

报

CHINESE JOURNAL OF COMPUTERS

2019Online Publishing No.34

基于深度学习的开放领域对话系统研究综述
陈晨 1),4) 朱晴晴 1) 严睿 2) 柳军飞 3)
1)
2)
3)

(北京大学 党委办公室校长办公室 北京 100871)

算
计

要

(北京大学 计算机科学技术研究所 北京 100871)

(北京大学 软件工程国家工程重点实验室 北京 100871)
4)

摘

(北京大学 软件与微电子学院 北京 100871)

人机对话系统能够让机器通过人类语言与人进行交互，是人工智能领域的一项重要工作。因其在虚拟助手和社交

聊天机器人等领域的商业价值而广受工业界和学术界的关注。近年来，互联网社交数据快速增长促进了数据驱动的开放领域
对话系统研究，尤其是将深度学习技术应用到其中取得了突破性进展。基于深度学习的开放领域对话系统使用海量社交对话
数据，通过检索或者生成的方法建立对话模型学习对话模式。将深度学习融入检索式系统中研究提高对话匹配模型的效果，
将深度学习融入生成式系统中构建更高质量的生成模型，成为了基于深度学习的开放领域对话系统的主要任务。本文对近几
年基于深度学习的开放领域对话系统研究进展进行综述，梳理、比较和分析主要方法，整理其中的关键问题和已有解决方案，

学
机

总结评测指标，展望未来研究趋势。
关键词

对话系统；聊天机器人；深度学习；序列到序列模型；匹配模型；对话系统评测

中图法分类号 TP391.1

Survey on Deep Learning Based Open Domain Dialogue System

1)
2)
3)

报

CHEN Chen1), 4) ZHU Qing-Qing1) YAN Rui2) LIU Jun-Fei3)
( School of Software and Microelectronics of Peking University, Beijing 100871)

( Institute of Computer Science and Technology of Peking University, Beijing 100871 )

( National Engineering Research Center for Software Engineering (Peking University), Beijing 100871 )
4)

( Principal Office of Peking University, Beijing 100871)

Abstract The human-machine dialogue system enables easy interaction interface between humans and
computers using natural languages, which is of growing significance in artificial intelligence. Owing to its
commercial value in the fields of virtual assistants and social chatbots, it has been widely concerned by business
and academia. Dialogue systems can be classified as domain-specific and open-domain models. Recently, along
with the fast prosperity of social media on the internet, research of data-driven open domain dialogue systems
has been promoted. In particular, as a major breakthrough, deep learning has proven to be an extremely powerful
tool in this field. The deep learning based open domain dialogue system directly constructs a dialogue model
———————————————
本文工作得到国家自然科学基金 (No. 61876196)资助. 陈晨(通信作者)，女，1985年生，博士研究生，助理研究员，主要研究领域为自然语言处理
E-mail: chenchen@pku.edu.cn. 朱晴晴，女，1995年生，博士研究生，主要研究领域为自然语言处理 .E-mail: zhuqingqing@pku.edu.cn. 严睿，男，1985
年生，博士，助理教授，是计算机学会(CCF)会员（会员号59604M）,主要研究领域为自然语言处理.E-mail: ruiyan@pku.edu.cn. 柳军飞，男，1965年
生，博士，教授，主要研究领域为软件过程 E-mail: liujunfei@pku.edu.cn.

计 算 机 学 报

2

2019 年

算
计

from query to reply by applying end-to-end deep learning techniques to processing massive dialogue data. Our
paper starts by summarizing the background and follows by introducing the state-of-the-art methods of
implementing the open domain dialogue system: retrieval-based, generation-based and the combination of both.
Then, we review the methods that can address several critical problems on this domain. After that, the evaluation
procedures of the open domain dialogue system are detailed. Finally, we end up with analyzing and forecasting
the future development trend that can bring the dialogue system research into a new frontier.
Key words Dialogue System; Chatbot; Deep Learning; Sequence-to-Sequence Model; Matching Model;
Dialogue System Evaluation
深度学习技术在检索和生成的方法中均有应
用，目前已成为开放领域对话系统领域的研究热点
1 引言
之一。近年来，深度学习技术的应用使得开放领域
对话系统取得了突破性进展，但由于研究时间短、
让机器具备与人交流的能力是人工智能领域
新的研究成果不断出现，已有的综述都未能全面而
的一项重要工作，同时也是一项极具挑战的任务。
深入进行总结。Chen 等人[3]针对所有对话系统进行
1951 年图灵在《计算机与智能》一文中提出用人机
综述，但是基于深度学习的开放领域对话系统仅为
对话来测试机器智能水平[1]，引起了研究者的广泛
其中的一部分，无论是模型还是关键问题都未能进
关注。此后，学者们尝试了各种方法研究建立对话
行深入描述和分析。张伟男等人[13]仅对对话系统的
系统。按照系统建设的目的，对话系统被分为任务
评价方法进行综述。Yan[2]对基于深度学习的开放领
驱动的限定领域对话系统和无特定任务的开放领
域对话系统进行综述，但是受篇幅限制未能从深度
域对话系统[2, 3]。限定领域对话系统是为了完成特
学习模型的角度进行详细地分类整理。本文以开放
定任务而设计的，例如网站客服、车载助手等。开
领域对话系统为研究对象，对基于深度学习的实现
放领域对话系统也被称为聊天机器人，是无任务驱
方法进行全面的回顾和分析，并详尽梳理开放领域
动，为了纯聊天或者娱乐而开发的，它的目的是生
对话系统中的关键性问题及解决方案，整理评价指
成有意义且相关的回复。
标，廓清本领域的发展状况与趋势，展望发展方向，
工业界将对话系统视作下一代人机交互的主
为未来的研究工作奠定基础。
要形式，近年来投入大量人力到相关研发工作中。

学
机

1.1 问题描述

本文的研究对象是开放领域的对话系统，首先
将其形式化描述为，在历史对话信息背景下，人将
无领域限制的话语作为查询（也可称为消息或问题
等）输入计算机，计算机返回对应的回复语句（也
可称为响应或回答）。以场景设置为标准，对话系
统可以分为单轮对话系统和多轮对话系统。单轮对
话系统将对话问题简化，只考虑找到给定查询的回
复。多轮对话系统需要综合考虑对话上下文（包括
历史对话信息和查询），建立对话的长期依赖关系，
给出更加符合对话逻辑的回复。
假设 q 表示作为查询的话语，r 表示回复话语，
c 代表历史对话信息，
 单轮对话：以 q 为前提，得到语句 r 作为回复；
 多轮对话：在 c 的背景下，以 q 为前提，得到
语句 r 作为回复。
表 1 给出中英文对话示例。

报

对话系统商业应用不断涌现，有不少产品已进入量
产阶段。在限定领域对话系统中，以苹果 Siri 和微
软 Cortana 为代表的语音助手已通过手机、操作系
统等媒介被人们广泛使用；另外，以亚马逊 Echo、
百度 Duer、谷歌 Home 和天猫精灵为代表的虚拟助
手式智能音箱也已走进千家万户。在开放领域对话
系统方面，微软针对不用语种开发了聊天机器人
xiaoice、rinna、Zo、Ruuh 等，使用用户达到数千
万。
在学术界，过去很长一段时间关于对话系统的
研究主要针对限定领域具体任务开展，是口语对话
系统的重要分支[4-7]。这些系统严格定义和限制接收
的输入，并针对特定任务设计相应的规则、逻辑和
回复语句[8]。虽然这些方法在人机交互上取得了很
大的进展，但受手工设定规则等方面的影响，其稳
健性、可扩展性和领域适应性都有缺陷，也不适用
于开放领域。近年来，随着互联网上社交数据的快
速增长，数据驱动的开放领域对话系统逐渐成为了
学术界关注的热点，人机对话系统也由服务的角色
逐步转变为情感伴侣的角色[9-12]。

表 1 中英文对话示例
中文

英语

陈晨等：基于深度学习的开放领域对话系统研究综述

3

件或者固定使用的标签，如果不具备相关知识库，
计算机将很难理解。

你今天好吗？

how are you today?

不错啊。你呢？

Not bad. How about you?

我很好。

Pretty good.

1.3 本文框架

那太好了。

That is great.

本文第 2 节概述相关深度学习技术。第 3 节介
绍基于深度学习的开放领域对话系统主要方法。第
4 节梳理基于深度学习的开放领域对话系统关键问
题。
第 5 节分类介绍开放领域对话系统的评测方法；
第 6 节展望基于深度学习的开放领域对话系统的未
来研究趋势。第 7 节是总结。

1.2 数据收集

算
计

传统的基于规则/模板的开放领域对话系统 [8]
需要手工制定规则,不需要大规模训练集。而数据驱
动的方法需要收集大量的对话数据。目前，互联网
上已经有大量记录人类交流的数据，其中的大部分
数据在经过预处理后，都可以被用到开放领域对话
系统的训练中。Luong 等人[14]将对话数据分成人机
对话和人人对话。现有的人机对话语料库主要是面
向任务的对话。本文主要针对开放领域对话，所以
接下来主要梳理人人对话数据资源。
人人对话数据可以进一步分为口语对话和书
面对话：
1) 口语对话：口语对话具有通俗、口语化特点，
说话者通常用对方的思路和方式讲话，倾向于
使用较短的单词和短语。其中比较有代表性的
数据集包括 Switchboard 电话对话数据集 [15]、
DSTC4-5 的 skype 通信数据集[16, 17]、康奈尔电
影 对 话 语 料 库 [18] 、 OpenSubtitles 网 站 1 上 的
OpenSubtitles 数据集[19]。
2) 书面对话：书面对话在书面交流中产生，它的
特点是用户可以在发送消息前反思他们正在
写的东西。书面对话语料可以进一步从来源进
行区分。例如文献[20-22]从 Twitter2网站上搜集
数据构造对话语料。Shang 等人[12]从新浪微博3
网站上搜集对话语料进行实验。文献[23, 24]
从聊天软件中收集关于 ubuntu 使用中遇到的
问题和相关回答。Song 等人[25]从豆瓣论坛4中
收集发帖和回复。
相比其他来源的语料，社交网站的对话数据容
易获取，使用者更多。但是这些数据存在不足，常
常包含拼写错误、缩略语等，还可能包含口语对话
中不会出现的场景表述。例如，用户可能会写“再
见并离开”
，而不是像口语表述时简单的说“再见”
[10]
。另外，社交网站的书面对话还包含近期热门事

2 深度学习技术
深度学习是机器学习的分支，是试图使用包含
复杂结构或由多重非线性变换构成的多处理层计
算模型对数据进行高层抽象的一类算法。深度学习
技术已被广泛应用到图像处理、语音处理、自然语
言处理等多个领域，取得了重大突破[26]。
2.1 神经网络语言模型

学
机

语言模型（Language Model，LM）把语料库当
作一个随机变量，对给定前面的词语预测下一个词
语的任务建模来计算句子概率。神经网络语言模型
（Neural Network Language Model，NNLM）最早
由 Bengio 等人[27]提出，其核心思路是用一个 K 维
的 向 量 来 表 示 词 语 ， 被 称 为 词 向 量 （ Word
Embedding）
，使得语义相似的词在向量空间中处于
相近的位置，并基于神经网络模型将输入的上下文
词向量序列转换成成固定长度的上下文隐藏向量，
使得语言模型不必存储所有不同词语的排列组合
信息，从而改进传统语言模型受词典规模限制的不
足。如图 1 所示。

报

图 1 神经网络语言模型示意图
1 http://www.opensubtitles.org
2 http://twitter.com
3 http://weibo.com
4 http://www.douban.com

2.2 自编码器
自编码器（Autoencoder, AE）是一种无监督的
学习模型，由 Rumelhart 等人[28]最早提出。自编码
器由编码器和解码器两部分组成，先用编码器对输

计 算 机 学 报

4

入数据进行压缩，将高维数据映射到低维空间，再
用解码器解压缩，对输入数据进行还原，从而来实
现输入到输出的复现。如图 2 所示，自编码器的训
练目标是，使得输出 X 尽可能地还原输入 X。其中，
编码器和解码器基于神经网络构建。

2019 年

方法将特征压缩。池化的方法包括加和池化、最大
池化、均值池化、最小值池化和随机池化。最后一
个池化层通常连接到全连接层，来计算最终的输
出。

图 2 自编码器结构示意图

算
计

为了改进基本模型中容易陷入局部最优的情
况，深度自编码器模型被提出[29, 30]。其中，变分自
编码器和条件变分自编码器被用到开放领域的对
话系统中，对回复生成的多样性进行控制，示意图
如图 3。变分自编码器[31]（Variational Auto-Encoder，
VAE）是一种生成模型，它引入统计思想在基础的
自编码器模型基础上加入正则约束项，使得隐层 z
满足某个分布，并从 z 中自动生成数据。条件变分
自编码器[31]（Conditional Variational Auto-Encoders，
CVAE）是在变分自编码器之上再加一些额外信息
为条件的一类模型。其模型训练和测试时候均以该
额外信息 c 为条件。

图 4 卷积神经网络应用示意图

不同研究中的卷积网络模型会有细微差别。以
文本表示为例，卷积神经网络在能从文本中提取隐
藏特征，形成低维向量表示。如图 4 所示，模型利
用局部特征抽取器通过滑动窗口获取变长序列的
隐藏特征，并经过池化得到定长输出。
2.4 循环神经网络

学
机

循 环 神 经 网 络 （ Recurrent Neural Network ，
RNN）是专门设计用于处理序列数据的神经网络架
构，它利用时间相对关系减少参数数目以提高训练
性能，已经成功的用于自然语言处理中[34]。

示意图

2.3 卷积神经网络
卷积神经网络（Convolutional Neural Network，
CNN）是人工神经网络的一种。其核心思想是设计
局部特征抽取器运用到全局，利用空间相对关系共
享参数，来提高训练性能。早期主要运用于图像处
理领域，后来被应用到自然语言处理中[32, 33]。
卷积层和池化层是卷积神经网络的重要组成部
分。其中，卷积层的作用是从固定大小的窗口中读
取输入层数据，经过卷积计算，实现特征提取。卷
积神经网络在同一层共享卷积计算模型来控制参
数规模，降低模型复杂度。池化层的作用是对特征
信号进行抽象，用于缩减输入数据的规模，按一定

报

图 3 变分自编码器（上）和条件变分自编码器（下）模型

图 5 循环神经网络模型示意图

循环神经网络具有自环的网络结构。一个简单
的循环神经网络如图 5 所示，左边为压缩表示，右
边是按时间展开的表示。其中，自环的网络对前面
的信息进行记忆并应用于当前输出的计算中，即当
前时刻隐藏层的输入包括输入层变量和上一时刻
的隐藏层变量。由于可以无限循环，所以理论上循
环神经网络能够对任何长度的序列数据进行处理。
循环神经网络在实际应用时有梯度消失等问题。后
续研究针对该问题提出带存储单元的循环神经网
络长短时记忆网络（Long Short-Term Memory，
LSTM）[35]和门控循环单元（Gated Recurrent Unit，

陈晨等：基于深度学习的开放领域对话系统研究综述

GRU）[36]。
循环神经网络在开放领域对话系统中可用于文
本表示，即将词向量按词语在文本中的顺序逐个输
入到网络中，末节点的隐藏向量可以作为该话语的
语义向量表示。随着技术的发展，其扩展模型双向
循环神经网络（Bi-LSTM）、密集循环神经网络
（DenseRNN）等都相继被引入到开放领域对话系
统中。

5

器 RNN 前一个时刻的隐藏向量与输入序列关联起
来，计算输入的每一步对当前解码的影响程度作为
权重，如图 7 所示。其中，前一时刻隐藏向量和输
入序列的关联方式有点乘[39]、向量级联方法[14]等。
最后，通过 softmax 函数归一化，得到概率分布权
重对输入序列做加权，重点考虑输入数据中对当前
解码影响最大的输入词。

2.5 序列到序列模型

算
计

序列到序列（Sequence to Sequence，Seq2Seq）
模型在 2014 年被 Cho 和 Sutskever 先后提出，前者
将 该 模 型 命 名 为 编 码 器 - 解 码 器 模 型
（Encoder-Decoder Model）[37]，后者将其命名为序
列到序列模型[38]。两者有一些细节上的差异，但总
体思想基本相同。具体来说，序列到序列模型就是
输入一个序列，输出另一个序列，它是一个通用的
框架，适用于各种序列的生成任务。其基本模型利
用两个循环神经网络：一个循环神经网络作为编码
器，将输入序列转换成定长的向量，将向量视为输
入序列的语义表示；另一个循环神经网络作为解码
器，根据输入序列的语义表示生成输出序列，如图
6 所示。

随着研究的深入，Vaswani 等人[40]将注意力机
制定义为一个查询到一组键值对的映射过程，并提
出了自注意力机制（Self-Attention），即其中的查询、
键、值是同一个句子，减少对外部信息的依赖，捕
捉数据内部的相关性。如图 8 所示，V、K、Q 分别
代表值、键、查询，若模型为自注意力则 V=K=Q。
Vaswani 等人[40]还提出了多头注意力机制，即分多
次计算注意力，在不同的表示子空间学习信息。多
头注意力机制先对输入做划分，依次经过线性变换
和点积后再拼接作为输出。

学
机

层次序列到序列模型在序列到序列模型基础上
定义了多层结构的编码器。首先，每个句子将其包
含的词序列向量表示输入循环神经网络得到该句
子的向量表示；然后，每个段落将其包含的句子序
列向量表示输入另一个循环神经网络得到该段落
向量表示。
2.6 注意力机制
通用的序列到序列模型，只使用到编码器的最
终状态来初始化解码器的初始状态，导致编码器无
法学习到句子内的长期依赖关系，同时解码器隐藏
变量会随着不断预测出的新词，稀释源输入句子的
影响。为了解决这个问题，Bahdanau 等人[39]提出
了注意力机制（Attention Mechanism）。注意力机制
可以理解为回溯策略。它在当前解码时刻，将解码

报

图 6 序列到序列模型示意图

图 7 注意力机制模型示意图

图 8 多头注意力机制模型示意图

2.7 记忆网络
记忆网络（Memory Network）[41]是指通过在外
部存储器模块中存储重要信息来增强神经网络的
一类模型。外部存储器模块具有内容可读写，信息
可检索和重用的特点。Sukhbaatar 等人[42]提出了一
个用于问答键值存储的端到端记忆网络架构
（End-to-End Memory Networks，MemN2N）
。其中

计 算 机 学 报

6

外部存储器以键-值对结构存储问答知识，可以检索
与输入相关的信息，得到相关度权值，然后获取将
对应的值加权求和作为输出。如图 9 所示，

2019 年

经典的强化学习建模框架如图 11 所示：在每
个时刻 t，智能体接收一个观察值 ot，收到一个奖
励值 rt，并执行一个动作 at；从环境的角度，它接
收智能体动作 at，给出下一个时刻观察值 ot+1 及对
应的奖赏 rt+1。由此，观察值、动作和奖赏一起构
成的序列就是智能体获得的经验数据，智能体的目
标则是依据经验获取最大累计奖励。

图 9 端到端记忆网络模型示意图

2.8 生成对抗网络

算
计

相对于其他的神经网络模型，记忆网络的外部
存储器可以构建具有长期记忆的模块（如知识库、
历史对话信息等）来增强神经模型。

近年，深度强化学习的诞生打破早期强化学习
模型不稳定难收敛的瓶颈，在人机博弈、无人驾驶、
视频游戏等很多任务上取得很好的效果。深度强化
学习的发展主要有两种路线：一种是以 DQN（Deep
Q-Leraning）[45]为代表的算法；另一种是策略梯度
方法（Policy Gradient Methods）[46]。策略梯度方法
通过梯度下降来学习预期奖励的策略参数，将策略
搜索转化成优化问题，并根据目标函数最优值确定
最优策略。相比而言，策略梯度方法更适合在自然
语言处理领域应用。

学
机

生 成 对 抗 网 络 （ Generative Adversarial
Networks，GAN,）[43]是 Goodfellow Ian 于 2014 年
提出的一种深度学习模型。它包含两个模块：生成
模型和判别模型。生成模型的训练目标是生成与训
练集中真实数据相似的数据。判别模型是一个二分
类器，用来判断这个样本是真实训练样本，还是生
成模型生成的样本，其训练目标是尽可能地区分真
实数据和生成数据。如图 10 所示，G 代表生成模
型，D 代表判别模型。

图 11 强化学习系统模型示意图

3 基于深度学习的开放领域对话系统

报

基于深度学习的开放领域对话系统以大规模对
话语料库作为训练语料，利用深度学习算法学习对
话模式。
图 10 生成对抗网络模型示意图

GAN 最早被用在图像处理领域，后来也被用到
自然语言处理领域中。与图灵测试的思想类似，在
开放领域对话系统中使用生成对抗网络的目标是
生成与人类回复无差别的回复。
2.9 强化学习
机器学习按学习范式可以分为有监督学习、无
监 督 学 习 和 强 化 学 习 。 强 化 学 习 (Reinforcement
Learning)[44]是指智能体通过和环境交互，序列化地
做出决策和采取动作，并获得奖赏指导行为的学习
机制。

图 12 基于深度学习的开放领域对话框架示意图

陈晨等：基于深度学习的开放领域对话系统研究综述

本文通过调研，将基于深度学习的开放领域对
话系统的描绘如图 12 分类。除了按输入是否考虑
历史对话信息分为单轮对话系统和多轮对话系统，
还可以根据构建方法可分为检索式、生成式和检索
与生成相结合的方法：
（1）检索式方法。检索式方法首先构建一个
供检索的对话语料库，将用户输入的话语视为对该
索引系统的查询，从中选择一个回复。具体来说，
当用户在线输入话语后，系统首先检索并初步召回
一批候选回复列表，再根据对话匹配模型对候选列
表做重排序并输出最佳回复。该方法重点在于让匹
配模型克服查询和回复之间的语义差异。流程框架
如图 13。

算
计

图 13 基于检索式方法的对话系统示意图

测阶段，系统根据对话模型计算输入语义向量，再
逐个生成词语组成回复话语。
（3）检索与生成相结合的方法。还有一些系统
不限于使用单一方法，而是将检索式和生成式方法
相结合构造开放领域对话系统。
本章对深度学习在每类方法中的应用情况进行
详细整理和分析比较。
3.1 深度学习在单轮检索模型的应用
基于检索方法的开放领域单轮对话系统与基
于检索方法的问答系统类似，对用户输入的查询先
检索再重排序给出最佳回复。单轮检索模型的核心
步骤是构建查询-回复的匹配模型，其中包含语义表
示模型和语义融合模型。语义表示模型将查询和回
复映射到语义向量；语义融合模型是对查询语义向
量和回复语义向量融合过程建模。将深度学习引入
到匹配模型中，可以增强匹配模型中语义表示和语
义融合计算的能力。Guo 等人[47]将匹配模型分为以
表示为中心和以融合为中心。本文发现还有一类系
统同时建立表示和融合为中心的匹配模型，最后结
合两者来计算匹配分数。相关文献分类整理如表 2。

学
机

（2）生成式方法。受到神经机器翻译的启发，
生成式方法的对话系统首先收集大规模对话语料
作为训练数据，基于深度神经网络构建端到端的对
话模型，来学习输入与回复之间的对应模式。在预

7

表 2 深度学习在单轮检索模型的应用
分类

Shen 等人

，Hu 等人
[49]

Wan 等人

[50]

Tan 等人
Yin 等人

循环神经网络

卷积神经网络、注意力机制

[52]

Kim 等人

循环神经网络、注意力机制、自编码器

Lu 等人[53]

深度神经网络

Hu 等人[32]，Pang 等人[54]

卷积神经网络

[55]，

Liu 等人

循环神经网络、记忆网络

[56]

Wang 等人

循环神经网络，注意力机制

[57]

Wan 等人
表示与融合相结合的框架

卷积神经网络

循环神经网络、卷积神经网络、注意力机制

[51]

以融合为中心的框架

深度学习模型

[32]

报

以表示为中心的框架

文献

[48]

[58]

Mitra 等人

空间递归神经网络
[59]

，Yu 等人

3.1.1 以表示为中心的框架
在表示为中心的单轮检索对话中，深度学习技
术被用于构建文本的语义表示模型，目的是基于查

卷积神经网络

询和回复的词向量矩阵输入捕捉句子隐含语义空
间的特征信息。框架如图 14 所示，其中 q 和 r 分别
表示查询和回复，s 表示匹配分数。

计 算 机 学 报

8

2019 年

[50]

图 15 Tan 等人

图 14 以表示为中心的单轮检索模型框架示意图

算
计

基于卷积神经网络。Shen 等人[48]基于卷积神经
网络将查询和候选回复的词向量输入通过卷积、池
化操作，得到其定长的语义表示向量，再使用余弦
相似度函数衡量查询和回复的匹配度。与之类似，
Hu 等人[32]提出的 ARC-I 模型将查询和候选回复输
入到卷积神经网络中计算出语义表示向量，然后用
多层感知器（Multi-Layer Perception，MLP）计算
匹配分数。
基于循环神经网络。Wan 等人[49]采用 Bi-LSTM
计算句子表示向量。其主要思想是，双向 LSTM 的
隐藏向量序列可以从不同位置表示该的句子语义，
使得语义融合过程考察不同位置语境下语义表示
的匹配，从而实现多位置匹配分数计算。作者在语
义融合时共使用了三种相似度计算算法：余弦值相
似度函数、双线性（Bilinear）和带张量参数的算法。
最终匹配分数计算是从匹配矩阵中挑选 K 个最大
的特征，再经 MLP 进行维度压缩得到。
基于循环神经网络+卷积神经网络/注意力机
制。Tan 等人[50]针对查询-回复匹配任务的提出四种
基于 LSTM 的语义表示模型：
（1）QA-LSTM：将
查询和回复分别输入 Bi-LSTM 后，再经过池化得
到 二 者 的 表 示 向 量 ；（ 2 ） Convolutional-pooling
LSTM：将查询和回复分别输入 Bi-LSTM 后，再经
过 CNN 模 型 得 到 二 者 的 表 示 向 量 ；（ 3 ）
Convolution-based LSTMs：将查询和回复先经过
CNN 计算，然后输入 Bi-LSTM 模型，再经过池化
得到表示向量；
（4）Attentive LSTMs：先将查询和
回复输入 Bi-LSTM，并用池化方法先计算查询的语
义表示向量，再利用注意力模型根据查询表示向量
计算回复的表示向量，使得回复的向量表示包含更
多与查询相关的信息量。上述四个模型中，Attentive
LSTMs 模型效果最好，其模型示意图如图 15 所示。

提出的 Attentive LSTMs 模型示意图

学
机

基于卷积神经网络+注意力机制。Yin 等人[51]
提出的 ABCNN 系列模型在用卷积神经网络进行语
义表示后，再使用注意力机制基于一个句子表示来
获得另外一个句子的表示，拓展表示信息。他们共
（1）ABCNN-1：在卷积前计算句子
提出三种模型：
间注意力权重矩阵，然后与原句子矩阵相乘得到其
注意力特征映射的矩阵，将这两个矩阵都传给卷积
（2）ABCNN-2：在池化层前采用与 ABCNN-1
层；
类似的方法，基于原句子矩阵计算含注意力特征的
矩阵，再将两个矩阵输入给池化层；
（3）ABCNN-3：
将 ABCNN-1 和 ABCNN-2 叠加，即卷积和池化前
都增加句子间注意力特征矩阵作为输入。
基于循环神经网络+注意力机制+自编码器 。
Kim 等 人 [52] 受 到 DenseNet[60] 的 启 发 提 出 基 于
DenseRNN 的通用框架匹配模型 DRCN。如图 16
所示，DRCN 模型包含多层 RNN+Attention 结构，
其中每层 RNN 的输入都是前面所有层输出的并集，
每层 RNN 的输出向量又都被直接传给语义融合前
的池化层作为输入。总的来说，该模型中句子语义
表示采用冗余的密集连接方式，整合所有
RNN+Attention 层的输出，相当于每层输出都直接
连接到损失函数，可以缓解模型层数增加带来的梯
度消失问题。DRCN 模型在合并输入时采用拼接的
方法将前面层输入和当前层包含注意力特征的表
示向量相结合。由于拼接操作会导致特征向量维度
不断增加，DRCN 模型还采用自编码器算法对输入
降维，每次将固定长度的向量传递给下一层，同时
还起到了正则化的作用。

报

陈晨等：基于深度学习的开放领域对话系统研究综述

[52]

图 16 Kim 等人

提出的 DRCN 模型示意图

3.1.2 以融合为中心的框架
以融合为中心的单轮检索对话用深度学习方法
对回复和查询语义融合过程建模，着力捕捉回复和
查询之间的语义融合信息，框架示意图如 17 所示。

9

算
计

学
机

等人[54]提出 MatchPyramid 模型。其主要思路是将
文本匹配任务类比为图像识别任务，首先基于词语
之间的相似性构造匹配矩阵，再利用卷积层和池化
层逐层捕获融合信息，计算匹配分数。
基于循环神经网络。Liu 等人[55]基于递归匹配
思路提出深度融合的 LSTM 匹配模型（DF-LSTM），
来模拟两个文本的强相互作用。具体来说，
DF-LSTM 由两个相互依赖的 LSTM 模型组成，这
两个 LSTM 分别用于捕捉两个词序列内部和外部的
语义表示和融合信息。假设，给定两个文本词序列
x1:m 和 y1:n，DF-LSTM 根据位置（i，j）之前的语义
融合信息来计算 x1:i 和 y1:j 的语义融合信息 hi,j。受
记忆网络模型的启发，该模型还引入两个外部存储
器来保存前面的语义融合信息。
作者认为 DF-LSTM
不仅能对相近词语之间语义进行融合匹配，还可以
捕捉复杂、长距离的匹配关系。
Wang 等人[56]基于循环神经网络提出了双边多
视角匹配模型（BiMPM）
。给定句子 P 和 Q，BiMPM
模型首先使用 Bi-LSTM 编码器对句子进行编码，
再进行 P 到 Q 和 Q 到 P 两个方向的匹配，然后用
另一个 Bi-LSTM 将匹配结果聚合成固定长度向量，
通过全连接层得到最终的匹配分数。BiMPM 一共
提出四种匹配方式，如图 18 所示。

图 17 以融合为中心的单轮检索模型框架示意图

报

基于深度神经网络。Lu 和 Li[53]最早使用深度神
经网络应实现以融合为中心的 DeepMatch 匹配模
型。其方法核心是，用语料预训练不同抽象层级的
话题模型，并根据这些话题模型检测待匹配文本的
共现话题，衡量查询和回复之间的共现关系，构造
语义融合矩阵，最后用深度神经网络计算匹配分
数。
基于卷积神经网络。Hu 等人[32]提出以语义融合
为中心的 ARC-II 模型。该模型分为三层，第一层
为卷积层，将查询和回复分别做一维卷积，然后针
对两者卷积得到的向量构造对应的特征组合，得到
一个二维的特征组合矩阵。第二层是池化层，对特
征组合矩阵进行最大池化操作。最后经过多次的卷
积和池化操作，得到两个句子语义融合的向量表
示，输入到 MLP 中，计算出匹配分数。作者的实
验表明，以融合为中心的 ARC-II 模型的匹配效果
要优于以表示为中心的 ARC-I 模型。
受卷积神经网络在图像识别领域的启发，Pang

[56]

图 18 Wang 等人

提出的匹配模型示意图

包括（1）完全匹配: 每个词语与待匹配句子的最后
一个隐藏层输出向量计算匹配度；（2）最大池化
匹配: 每个词语与待匹配句子的每一个单词进行匹
配度计算，再取最大值；（3）注意力匹配: 每个词

计 算 机 学 报

10

算
计

语与待匹配句子的每个单词计算余弦相似度，然后
用 Softmax 归一化，作为注意力权重加权求和得到
注意力向量表示，与词语计算匹配度；（4）最大
注意力匹配: 每个单词与待匹配句子中的每个单词
计算余弦相似度。然后用 Softmax 归一化，作为注
意力权重，取最大值，得到的结果再与词语计算匹
配度。作者将这四种匹配方式组合在一起得到最好
的实验效果。
基 于 递 归 神 经 网 络 。 Wan 等 人 提 出 的
Match-SRNN[57] 模 型 基 于 空 间 递 归 神 经 网 络
（Spatial RNN）进行文本语义融合计算。该模型将
文本融合计算看作一个递归的过程，即每个位置的
两个文本的相互作用是它们的前缀之间的语义融
合以及当前位置的单词语义融合结果的组合。作者
在实验中还尝试结合从前往后和从后往前两个方
向的匹配模型（Bi-Match-SRNN）
，达到了最优的效
果。
3.1.3 表示与融合相结合的框架
一些模型分别实现以表示中心的模型和以融合
为中心的模型，再将其组合起来。
基于卷积神经网络。Mitra 等人[58]提出包含两
个子匹配模型的排序模型。其中，基于单词精确匹
配的子模型被称为本地模型，属于以融合为中心的
模型；基于词向量的子模型被称为分布式模型，是
以表示为中心的模型。两个子模型联合训练，分别
通过卷积、池化等深度学习技术计算匹配分数，再
将两个子模型的匹配分数相加作为最终匹配分数。
Yu 等人[59]基于组合表示和融合相结合的模型
实现了检索式问答匹配的跨领域迁移学习，利用已
有的标注数据来优化其他领域小规模数据的检索
对话效果。模型中的匹配分数计算结合以表示为中
心的模型和以融合为中心的模型。如图 19 所示，
左边为以表示为中心的模型，右边为以融合为中心
的模型，均基于卷积神经网络技术实现。

2019 年

[59]

图 19 Yu 等人

提出的表示和融合相结合的模型示意图

学
机

3.1.4 分析比较
从框架层面看，早期研究中以语义融合为中心
的模型能够充分的保留查询与回复之间的语义融
合匹配信息，匹配效果要好于以表示为中心的单轮
检索模型。就计算效率而言，以表示为中心的模型
能够通过预训练将回复语料库提前表示成向量，且
语义融合计算较简单，比以融合为中心的模型更适
合在线检索回复的任务。近期，随着注意力机制的
深入研究，融入注意力机制以表示为中心的模型[52]
达到了最先进的性能。除此之外，还有一些系统同
时构建以表示为中心和以融合为中心两个自子系
统，捕捉不同方面的匹配度，来提升系统性能。
从在语义表示和融合的具体应用来看：
（1）深度学习在单轮检索对话中的语义表示应
用主要基于卷积神经网络、循环神经网络和注意力
机制。其中，卷积神经网络的层级结构具有较好的
特征选取能力，可以并行计算，运行速度快，但无
法捕捉长距离依赖关系；循环神经网络能够捕捉长
距离依赖关系，更适合序列建模，但特征提取能力
稍弱。注意力机制则可与卷积神经网络、循环神经
网络相结合，对关键信息进行筛选，提升语义的表
达性能。
（2）单轮对话检索方法的深度语义融合最早基
于深度神经网络，后来提出的模型包括卷积神经网
络、循环神经网络和递归神经网络。卷积神经网络
直接基于匹配矩阵提取句子级别匹配特征；循环神
经网络的匹配模型则有多种匹配方式，其中递归匹
配的方式较符合序列匹配思路，被多个研究采用。

报

3.2 深度学习在多轮检索模型中的应用
与单轮检索对话模型类似，多轮检索模型同样
遵循检索-匹配-重排序的操作流程。相关研究大多

陈晨等：基于深度学习的开放领域对话系统研究综述

11

下面将对话的多轮检索模型分为以表示为中
心、以融合为中心和面向重排序三类框架展开介
绍。相关文献分类整理如表 3。

将深度学习技术应用在匹配过程中，少数用在重排
序步骤。与单轮模型最大的区别在于，多轮对话系
统需要整合当前的查询和历史对话信息作为输入，
目标是选择既与查询相关，又符合历史对话语境的
语句作为回复。

表 3 深度学习在多轮检索模型的应用
分类

文献

以表示为中心的框架

以融合为中心的框架

深度学习模型

[24]

Lowe 等人

[61]

，Inaba 等人

循环神经网络

Zhou 等人[62]，Yan 等人[63]

卷积神经网络、循环神经网络

Wu 等人[64]

卷积神经网络、循环神经网络

[65]

Zhang 等人

循环神经网络、注意力机制

[66]

Zhou 等人
以融合为中心的框架

注意力机制

[67]

Yan 等人

算
计

3.2.1 以表示为中心的框架
以表示为中心的多轮检索模型着力于用深度
学习模型将对话上下文信息表示成语义向量，再计
算其与回复的匹配分数，框架示意图如图 20：

卷积神经网络、循环神经网络

学
机

回复。其中，基于词序列的视角将文本中所有词按
顺序输入到一个 GRU 中，将其隐藏向量作为文本
的语义表示；话语序列的视角则基于卷积神经网
络，先通过卷积和池化得到每个话语的表示，再输
入到另一个 GRU 中输入文本的表示。
Yan 等人[63]提出用历史对话信息来重构查询的
思路实现多轮检索对话。其主要思路是，基于历史
对话重构的查询可以捕捉历史对话中不同方面的
特征信息，在回复选择时综合考虑原始查询和重构
的查询，可以增强回复与历史对话语境的相关性。
假设历史对话信息 c 中有 N 个句子，作者用 5 种方
法重构新查询集合：
（1）无历史对话：不加入 c 中
的句子；
（2）全部历史对话：加入 c 中全部的句子；
（3）加一条：每次加一个 c 中的句子；
（4）减一
条：每次加 N-1 个 c 中的句子；
（5）上述四种方法
结合。具体来说，该模型首先将句子的词序列输入
到 Bi-LSTM 中，再使用卷积神经网络具体得到句
子的向量表示。并根据重构方法得到重构查询集
合，将集合中的重构查询与候选回复、先前帖子、
原始查询的向量表示分别拼接，经过 MLP 后整合
成最终的匹配分数。
3.2.2 以融合为中心的框架
以融合为中心的多轮检索模型着力于计算回复
与对话上下文中话语的语义匹配特征。相比以表示
为中心的模型，该框架计算回复与每个话语的融合
信息，在更细的语义融合粒度上计算对话上下文信
息与回复的匹配分数。如图 21 所示。

图 20 以表示为中心的多轮检索模型示意图

报

其中，u1,u2,u3 表示对话上下文话语，r 表示候选回
复。
基 于 循 环 神 经 网 络 。 Lowe 等 人 [24] 在 发 布
Ubuntu 多轮对话数据集的同时提出基于 RNN 的基
准模型（Baseline Model）
。该模型不区分历史对话
信息和查询，将其拼接在一起作为输入，首先基于
TF-IDF 模型找出相似度最高的候选回复，再用
RNN/LSTM 模型将句子转为向量表示计算匹配分
数。Inaba 等人[61]提出了基于 RNN 编码器框架的神
经对话排序模型。其基本思想是，用构建两层 RNN，
一层用于提取文本向量表示，在另一层用于候选回
复排序。
基于卷积神经网络和循环神经网络。Zhou 等人
[62]
提出了多视角的多轮对话检索模型。该模型将对
话上下文信息作为输入，并从词序列和话语序列两
个视角来计算匹配分数，最终结合两个分数来选择

计 算 机 学 报

12

图 21 以融合为中心的多轮检索模型示意图

基于卷积神经网络和循环神经网络。Wu 等人
提出序列匹配网络（Sequence Matching Network，
SMN）框架实现了以语义融合为中心的多轮检索对
话系统，如图 22 所示。序列匹配网络的主要思想
是，首先对候选回复与上下文中的每个话语分别计
算语义融合得到匹配矩阵，再用卷积和池化操作提
取每个话语-回复对的重要匹配信息，然后按话语在
上下文中的顺序依次输入到一个 GRU 中累计这些
匹配信息，从而得到整个上下文和候选回复之间的
匹配关系。最后，基于 RNN 的隐藏层向量计算最
终的匹配分数。
[64]

2019 年

算
计

出最终的候选回复匹配分数。
基于自注意力机制。受到机器翻译系统
Transformer[40]的启发，Zhou 等人[66]打破循环神经
网络和卷积神经网络结构，仅基于注意力机制实现
了多轮检索对话的匹配模型。该模型的语义表示基
于多层的自注意力机制，即将句子的词向量矩阵经
过多次自注意力计算得到一组句子表示矩阵。其语
义融合的过程构建两种匹配矩阵来提取上下文和
查 询 的 匹 配 特 征 ：（ 1 ） 自 注 意 力 匹 配
（self-attention-match）直接将自注意力得到的话语
和回复表示矩阵点乘得到匹配矩阵；
（2）交叉注意
力匹配（cross-attention-match）计算话语投影到回
复的表示矩阵和回复投影到话语的表示矩阵。这两
个表示矩阵能够捕捉话语和回复语义结构，使得有
依赖关系的段在表示中相互接近，从而得到基于依
赖关系的匹配矩阵。最后将匹配矩阵组合起来，经
过最大池化和感知机得到最终的匹配分数。

学
机

3.2.3 基于重排序的框架
深度重排序模型。Yan 等人[67]提出一种排序重排序模型，先根据查询检索出候选回复，再根据
历史对话信息，对候选回复进行重新排序，使得最
终给出的回复不仅和查询相关，也和历史对话语境
相关。该文中句子建模可采用循环神经网络、卷积
神经网络等深度学习模型。这种方法中，粗粒度地
候选回复筛选仅与查询有关，历史对话信息对回复
的影响有限，相关研究也很少。
3.2.4 分析比较
从框架层面看，以表示为中心的多轮检索对话
模型，在语义表示计算过程与回复独立，会丢失一
些特征。以融合为中心的多轮检索对话模型能够提
取和保留上下文中对匹配回复有用的信息，较前者
匹配效果更好，但是算法更复杂、计算量更大。
从深度学习技术的具体应用来看：
（1）多轮检索对话中的深度学习语义表示模
型用到循环神经网络、卷积神经网络、注意力机制。
与单轮对话不同，多轮检索对话需要对历史对话话
语和查询的组合方式建模，其组合方式可以分为：
a）直接拼接为词序列：由于不同历史对话与查询
的相关性不同，直接拼接会引入噪音；b）合并为
话语序列：将历史对话和查询视作话语序列，这中
方法也降低了查询对回复的影响；c）根据历史对
话对查询进行扩展：这种方法复杂度较高，很难穷
举所有的对话历史选择可能性，而仅扩展有限的查

报

[64]

图 22 Wu 等人

提出的序列匹配模型示意图

基于循环神经网络和注意力机制。Zhang 等人
提出的多轮检索对话模型中，语义表示和语义融
合过程均用深度学习模型。在语义表示过程中，模
型首先将查询分别与对话历史话语和回复拼接，并
先后采用自注意力机制和 GRU 得到每个话语的语
义表示；语义融合过程则是基于词粒度和句粒度两
个匹配矩阵，用卷积、最大池化和扁平化方法计算
出每个话语与查询的匹配特征向量。最后，将话语
和查询的匹配特征向量按顺序输入到 GRU 中计算
[65]

陈晨等：基于深度学习的开放领域对话系统研究综述

13

3.3 深度学习在单轮生成模型中的应用

询组合提升性能有限；d）基于注意力机制将查询
与对话历史话语逐一组合：该方法能够弥补前面方
法的不足，根据对话历史话语与查询的相关性，计
算对话上下文的语义表示，减少噪音影响。
（2）随着研究的深入，多轮检索对话中的语
义融合计算越来越复杂，使用的深度语义融合模型
包括循环神经网络、卷积神经网络和注意力机制。
其中，循环神经网络可根据上下文话语顺序来计算
匹配度，卷积神经网络则直接根据匹配矩阵提取特
征。近期研究表明，应用自注意力机制的模型达到
了当前最优的匹配性能[64]。

受到基于短语的统计机器翻译技术 [68] 启发，
2011 年 Ritter 等人[69]提出一个生成回复的概率模
型。它将生成回复视为翻译任务，即将输入查询翻
译成回复。但是由于对话回复多样性的特点，该任
务比翻译任务要更困难，所以直到基于深度神经网
络模型的成功，才真正激发学者们对生成式对话系
统的研究热情。根据系统实现的基础框架，本文将
单轮生成模型序列到序列模型框架、神经语言模型
框架和强化学习框架三类，相关文献整理如表 4。

表 4 深度学习在单轮生成模型的应用
分类

文献
[12]

序列到序列模型框架

Shang 等人

深度学习模型
[70]

，Shao 等人

[71]

，Wang 等人

[72]

Wu 等人

，

序列到序列模型、循环神经网络、注意力机制

[73]

，Shang 等人

Mei 等人[74]

算
计

神经语言模型框架

神经语言模型、循环神经网络、注意力机制

强化学习框架

[75]

Li 等人

，

[76]

Li 等人

，Xu 等人

强化学习、序列到序列模型
[77]

全局编码器训练不充分，所以提出先分别训练两个
子模型，再将两者合并利用微调的方法优化。训练
阶段以给定查询最大化训练集中真实回复概率为
目标，预测阶段则采取集束搜索(Beam Search)的方
法来生成回复。
注意力机制纳入部分目标序列。Shao 等人[70]
注意到基本的序列到序列模型中，解码器没有将生
成词纳入到注意力的计算中，导致很难生成信息量
大的长回复。他们提出将已生成序列作为一部分加
入到注意力机制的关注中。该模型具有固定长度的
解码器，且编码器最后一个节点的隐藏向量始终直
接连接解码器的初始向量，如图 24 所示：

学
机

3.3.1 序列到序列模型框架
绝大多数的单轮对话生成基于序列到序列模
型框架建立端到端的对话模型，根据给定的查询语
句生成回复。
引入注意力机制。Shang 等人[12]最早基于新浪
微博构建语料库，并采用序列到序列模型框架实现
单轮对话生成系统。模型首先用编码器 RNN 对查
询进行编码得到其语义向量表示，再用解码器 RNN
对该语义向量解码得到回复序列。模型解码器 RNN
在每个时刻输入的语义向量包含两个来源：一是全
局编码器（global encoder）计算的全局语义向量，
二是局部编码器（local encoder）基于注意力机制加
权计算的局部语义向量，如图 23 所示：

生成对抗网络、序列到序列模型

报

[70]

图 24 Shao 等人
[12]

图 23 Shang 等人

提出的单轮对话生成模型示意图

作者认为将全局编码器和局部编码器同时训练时，
5

http://weibo.com

提出的对话生成示意图

具体来说，在训练时，作者将输出序列分割成固定
长度且不重叠的连续片段构造新的训练数据。假设
回复 y 被分割成 y1 和 y2，则查询-回复对 x->y 分
割后将形成两对训练数据 x->y2 和 x,y1->y2。在预

计 算 机 学 报

14

算
计

测时，片段内采用集束搜索，片段级别使用归一化
分数进行重排序。
动态的解码器词典。在序列到序列模型框架下，
解码所有回复的词语都从相同的词典生成。为了保
证回复多样性，词典规模大，解码成本高，也容易
受到噪声影响。Wu 等人[72]对解码阶段的词语映射
进行改进，提出一种基于动态解码词典的序列到序
列模型（DVS2S），使得每步解码根据当前对话实
际有不同的词典，以去除不相关词汇的干扰，缩小
映射范围，加快解码速度。在训练时，该模型同时
学习动态词典构建和回复生成。在预测中，模型使
用预测模型动态地为输入分配相应的小词汇表，并
且仅使用小词汇表进行解码。作者的实验结果表明
在不影响解码质量的情况下，在线解码生成的速度
提高 40%。
增加校准机制。Shang 等人[73]针对对话语料库
中包含噪音的情况提出校准机制。其主要思想是，
用基于深度神经网络的对话质量评价指标对训练
语料中的查询-回复对打分，根据其分值高低决定训
练时对模型的影响程度。框架示意图如图 25 所示，
训练时，系统根据训练数据的打分来对损失值加权
反馈给模型。

2019 年

学
机

文语义向量，然后根据该向量和 RNN 模型的隐藏
向量计算输出。与序列到序列框架的注意力模型相
比，这种方法的特点是为每个生成步骤提供不同的
输入做参考。作者还预训练话题模型，在文档级别
选择最佳话题匹配作为生成回复，保证话题延续。
3.3.3 基于强化学习框架
在强化学习框架下，系统可以与外部环境交
互，通过做出决策、采取动作、获得奖赏来指导和
改进模型。
基于强化学习。Li 等人[75]在生成式对话系统中
引入强化学习模型来整合奖励策略并建立长期影
响机制。该模型使用序列到序列模型学习对话中的
语义关系，使用强化学习模型优化长期对话机制。
作者提出从三个方面来评价对话，1)连贯性：连续
轮转之间的语义相似性；2)信息流：同一个人的话，
应该在语义上移动避免语义重复；3)轻松回答：话
语能很容易给出好的回复。模型采用策略梯度方法
来奖励表现良好的回复。该模型基于预定义的评价
指标作反馈，这种人为定义的评价标准比较死板。
基于生成对抗网络。Li 等人[76]采用对抗学习[43]
的思想，同时训练的回复生成器和回复判别器两个
模型。其中，生成器是基于序列到序列模型的生成
式对话模型；判别器是一个二分类模型，将生成的
回复分为人回复和机器回复两类，用于评估回复的
质量。该框架的关键思想是鼓励生成器生成与人类
回复无法区分的话语。Xu 等人[77]也将生成对抗网
络用到对话生成任务，它提出用近似嵌入层来代替
解码器中的采样解码结果,整个模型连续可导，使得
判别器可以将误差反向传播到生成器。
3.3.4 分析比较
单轮生成对话任务中使用的深度学习技术包括
神经语言模型、循环神经网络、注意力机制、生成
对抗网络。虽然 Mei 等人[74]提出基于神经语言模型
的对话生成效果要优于序列到序列模型的对话生
成效果，但是绝大多数的系统还是改进序列到序列
框架。
针对序列到序列框架的改进可以分为两大类：
一类是对模型效果的改进，相关工作包括改进编码
器、引入注意力机制、改进解码器、数据校准等；
一类是对模型效率的改进，例如通过使用动态词典
来提升系统的解码速度。
基于强化学习框架的单轮对话生成系统在序列
到序列模型基础上引入反馈机制，能够进一步改进
模型效果。

报

[73]

图 25 Shang 等人

提出的单轮对话生成模型示意图

3.3.2 神经语言模型框架
神经语言模型对给定前面的词语能预测下一
个词语，所以可以直接基于该框架建立生成式模
型。
基于循环神经网络语言模型+注意力机制。Mei
等人[74]基于 RNN 的神经语言模型同时加入动态注
意力机制实现单轮对话生成系统。其主要思路是建
立一个基于 RNN 的语言模型，将词序列按顺序输
入模型计算隐藏向量，并在每个解码时刻对所有前
面的隐藏向量应用注意力机制，计算出赋权的上下

陈晨等：基于深度学习的开放领域对话系统研究综述

3.4 深度学习在多轮生成模型中的应用

15

话系统分为基于序列到序列模型框架、基于神经语
言模型框架和基于层次序列到序列模型框架，相关
文献如表 5。

真实对话通常有多轮，对话回复需要考虑历史
对话信息，近期的生成式对话研究也重点关注多轮
对话任务。根据系统实现框架，本文将多轮生成对

表 5 深度学习在多轮生成模型的应用
分类

文献

深度学习模型

[78]

序列到序列模型框架

Vinyals 等人

，Yao 等人

[79]

循环神经网络

Wang 等人[71]，Yan 等人[80]
Sordoni 等人[21]

神经语言模型框架
层次序列到序列模型框架

循环神经网络、注意力机制

[81]

Serban 等人

[82]

，Serban 等人

神经语言模型
[83]

，Serban 等人

[84]

，Tian 等人

循环神经网络、注意力机制

[85]

Chen 等人

算
计

3.4.1 序列到序列模型框架
基于基本的序列到序列模型。Vinyals 等人[78]
最早基于序列到序列模型的构建多轮对话生成系
统。他们的模型基于循环神经网络，将对话上下文
统一作为输入，一次读取一个词语。在训练期间用
真实回复中的上一个词作为预测时的输入；在预测
时用上一个词的预测输出作为当前时刻输入。该模
型较简单，但是却为许多问题生成了恰当的答案，
开启了利用深度学习技术构建生成式对话系统的
研究。
融入意图网络的序列到序列模型。Yao 等人[79]
提出的多轮对话生成模型包括三个模块：编码器、
意图网络和解码器。每个模块都使用循环神经网
络。其中编码器和解码器的构建与 Vinyals 等人[78]
提出的模型一样，意图网络用于记忆对话意图历史
信息。
多信道编码器。Wang 等人[71]对对话语料进行
分析，发现上下文中只有不超过 45.2％的短语直接
有助于回复生成，于是提出在序列到序列模型的编
码器上增加深度信道（Deep Channel）和宽度信道
（Wide Channel）来进一步提取对生成回复有用的
信息。其中，宽度信道采用带注意力机制的循环神
经网络来预测没有出现在对话中，但与输入话语相
关的关键字；深度信道则通过训练多层感知器模型
来选择输入话语中已有的词作为关键字。最后，将
深度信道和宽度信道预测的关键词和输入话语一
起传给解码器，再用注意力机制的解码器来生成回
复。
利用对偶序列到序列模型进行对话建议。Yan
等人 [80] 对给定上下文信息输出回复的基本对话范

循环神经网络、记忆网络

学
机

式进行扩展，提出了上下文-回复-对话建议的范式。
其主要思想是，在上下文编码器和生成回复解码器
外，加入一个基于深层双融合单元的序列到序列模
型作为对话建议的解码器，对当前回复的下一个回
复进行预测。具体来说，作者提出的深层双融合单
元包括：顺序 GRU 单元、对齐 GRU 单元以及融合
单元。该单元能够深度融合来自双序列的信息，并
解码生成对话建议。
3.4.2 神经语言模型框架
基于神经语言模型。Sordoni 等人[21]在 2015 年
提出了基于神经语言模型的多轮对话生成模型。作
者共提出三种组合历史对话话语和当前查询的方
法来训练神经语言模型。在预测阶段，模型计算概
率最大的语句作为回复。三种方法如图 26 所示：

报
图 26 Sordorni 等人

[21]

提出的多轮对话生成模型示意图

（1）RLMT：将历史对话话语-查询-回复串联起来，
训练神经语言模型。（2）DCGM-I：基于神经网络
模型将将历史对话话语-查询合并表示成固定长度，
训练神经语言模型。
（3）DCGM-II：将历史对话话
语和查询分别经过线性映射再拼接成固定长度向
量，作为神经语言模型的输入。其中，RLMT 和
DCGM-I 模型不区分历史对话话语和查询，会减弱

计 算 机 学 报

16

算
计

查询和回复之间的依赖关系，DCGM-II 也仅仅将历
史对话话语和查询做简单区分。
3.4.3 层次序列到序列模型框架
Li 等人[86]提出的层次编码器-解码器模型对文
本序列的层次结构建模，可直接对多轮对话系统建
模。不少研究工作基于该模型开展。
基于层次序列到序列模型。Serban 等人[81]基于
层次序列到序列模型构建了对对话上下文话语序
。该模型包含（1）话
列建模的对话模型（HRED）
语级模型（Encoder RNN）
：基于循环神经网络将单
个话语中包含的词序列向量表示转换成话语的向
量表示，主要用来捕捉每个话语的表示语义；
（2）
话语间模型（context RNN）
：基于循环神经网络将
多个话语的向量表示转换成对话上下文的向量表
示，用来将历史对话和查询的信息集成在一起。最
后，将根据话语序列顺序计算的上下文表示输入到
解码器（decoder RNN）中解码。但是，HRED 模
型相对于标准的序列到序列模型性能提高并不明
显。
Serban 等人[82]认为 HRED[81]模型回复生成词
语时的采样是浅层的，提出了基于潜在变量的层次
编码器解码器模型（VHRED）。该模型在 Context
RNN 中引入一个随机变量，解码过程先采样出潜在
变量，再生成序列。其中的潜在变量可以是情感或
话题，能对回复进行初步分类。由于 VHRED 可以
通过潜在变量分布对对话中的不确定性建模，故能
生成信息更丰富的回复。
Serban 等人[83]继续对 VHRED 做改进提出了
MrRNN 模型。MrRNN 由两个并行的 HRED 模型构
成：一个对粗粒度序列建模（作者定义为文本中的
名词序列或谓词-参数对）；另一个对完整词序列建
模。其中，完整词序列 HRED 中的解码基于粗粒度
序列 HRED 模型的解码结果。根据约束条件，粗粒
度序列包含更多的语义信息，能够缓解自然语言的
稀疏性问题，所以 MrRNN 表现出更好的性能。
Tian 等人 [84] 通过计算历史对话话语与查询相
似度作为权重来来衡量话语对生成回复的重要程
度，再基于权重来整合对话上下文表示，最后基于
层次序列到序列模型实现多轮对话生成。具体来
说，该模型先将历史对话话语和当前查询表示成向
量形式，用余弦相似度计算相似度作为权值，最后
用加权求和/加权拼接的方式整合历史对话信息和
查询。
基于层次序列到序列模型+记忆网络。Chen 等

2019 年

人 [85] 提出在层次序列到序列模型中增加变分记忆
网络的模型（HVMN）
，HVMN 将变分自编码器[87]
和记忆网络[42]结合起来跟踪对话的长期记忆，实现
对历史对话高级抽象信息的存取。具体来说，先根
据编码器隐藏向量 h 计算出潜在变量 z，再将 z 和
记忆网络 M 结合计算出变分记忆网络模块的输出
b，如下图所示。最后根据 b、上下文向量表示、上
一时刻解码输出和上一时刻解码隐藏向量一起预
测当前时刻输出。如图 27 所示。

图 27 Chen 等人

[85]

提出的记忆网络模块示意图

学
机

3.4.4 分析比较
深度学习在多轮对话生成中的应用主要包括
神经语言模型、序列到序列模型、注意力机制和层
次序列到序列模型。早期的模型大多基于不分层的
结构（包括神经语言模型和序列到序列模型）。但
是，在不分层的框架中，无论是直接拼接历史话语
和查询，还是按顺序接收话语作为输入，都会减弱
查询和回复之间的依赖关系，引入噪音。近期的多
轮对话生成模型大多基于层次序列到序列模型框
架实现，并通过改进该框架来优化对话上下文的向
量表示。将基于层次框架的模型和基于不分层框架
的模型相比，改进的层次框架模型对话语层级关系
直接建模，效果更好，能生成更多样、更有意义的
回复。

报

3.5 检索与生成相结合的方法
3.5.1 单方法模型分析
基于检索方法的对话系统中回复是人的真实话
语，所以语句质量较高，语法错误少，是目前工业
应用的主流技术。但是检索的方法的前提是预设对
话语料库中存在能作为回复的话语，也就是说，大
规模语料库是检索式系统成功的关键 [9] 。有限的存
储规模成为检索数据库无法突破的瓶颈。也就是
说，即使检索存储库非常大，如果对给定的查询话
语没有适当的回复时，系统也不能创建新回复。
生成式对话系统逐渐成为研究者关注的热点。
然而虽然生成式对话系统取得很大进展，能够“创

陈晨等：基于深度学习的开放领域对话系统研究综述

算
计

造性”地生成回复。其优势包括使用和维护成本低、
可覆盖任意话题的查询。缺点是生成回复质量不可
控，甚至可能有语句不通顺、句法错误等问题。具
体来说：
（1）倾向于生成缺乏语义信息的“万能回复”
。
由于生成式对话系统生成回复的过程不可控，系统
直接从训练数据中学习模式生成回复，而“我不知
、
“好的”等缺乏语义信息的“万能回复”在训
道”
练数据中出现的频次较高，最大似然估计的方法使
得模型倾向于生成这样的回复[88]。
（2）生成句子的质量不能保证。基于生成的系
统较为灵活，可以在相对较小的词汇表和较小的训
练数据集的情况下创建无限回复。然而，生成的句
子并不总能保证是自然的，流畅的和合理的[63]。
（3）生成式方法的训练和预测的解码过程不一
致影响生成质量。生成式对话系统的回复话语生成
的过程对应着序列到序列模型中的解码过程，而实
际训练和预测过程中，解码方法不完全相同。训练
时，输入对应的输出已知，所以每一个词语生成时，
使用真实上一时刻输出词作为当前时刻的输入；而
在预测阶段输出未知，通常采用集束搜索方法来解
码 [12]。另外，生成式方法在训练模型时使用词语
级别损失函数，测试时通常采用序列级评估指标，
二者不完全统一。
3.5.2 检索与生成相结合的方法
一些研究尝试将检索式方法和生成式方法集成
起来建立开放领域对话系统，目标是结合检索模型
和生成模型的优点。Song 等人[25]使用检索模型检索
到的候选结果和查询同时作为序列到序列模型中
编码器的输入生成结果，然后再将该生成结果加入
原检索候选集中，进行重新排序，使得对于一个输
入，系统能够从不同的渠道输出优化的结果，从而
提升回复质量。Cho 等人[89]同样将两个模型进行融
合，先通过传统的检索模型从问答知识库中找出候
选答案集合，然后训练带注意力的序列到序列的生
成模型对候选答案进行重排序。在选择回复时，如
果第一候选回复的得分超过某个阈值，就直接输出
该回复，否则利用生成模型生成结果作为回复。

为基础建立最大化语料库概率的对话模型。但由于
对话语料库没有根据场景、目的、个性化等特征信
息做区分，使得建立的对话模型存在一些关键问题
待解决。
4.1 回复多样性
开放领域对话系统最典型的特点是，对于用户
给定的查询，存在多个合理的回复，这种现象被称
为“一对多（One-to-many）
”的多样性。检索式对
话系统的回复内容控制可以通过选择不同的候选
回复实现。而对于生成式对话系统，模型的特点决
定其倾向将出现概率更大的通用话语作为回复，诸
如“我不知道”、
“我也是”等通用回复。Li 等人[88]
对对话语料分布进行分析，他们的数据中有 0.45%
的回复是“我不知道”，而相对信息量更大的其他
回复则出现概率较小。虽然通用回复也是合理回
复，但是没有太大的意义。所以提高回复多样性是
提升生成式对话系统效果一直在努力的方向。
最大互信息目标函数。在生成式对话系统中，
降低通用回复概率最直接的方法是找到一个更好
的目标函数。Li 等人[88]提出一种基于最大互信息的
优 化 目 标 ， 将 标 准 目 标 函 数 log 𝑝(𝒓|𝒒) 修 改 为
log 𝑝(𝒓|𝒒) − log 𝑝(𝒓)。这种方法使得被选中的回复
不仅取决于给定用户查询生成回复的概率，也取决
于给定回复生成用户查询的概率，以限制通用回
复，从而提升回复信息多样性。
改进排序规则。改进候选回复的排序规则也可
以实现对话内容控制。检索式对话系统可以直接改
进候选回复的排序。而生成式对话系统改变候选排
序在解码阶段完成。序列到序列解码用到的集束搜
索算法会产生冗余的候选回复，可以从中挑选出具
有多样性特征的回复。
一些研究通过改进集束搜索来提高模型性能。
Vijayakumar 等人[90]认为对话生成不是唯一正确答
案的任务，提出用一个度量候选序列之间多样性差
异的方法扩大集束搜索的搜索目标，来探索不同路
径解码结果来避免局部最小值。Shao 等人[70]结合
优化过的解码模型引入随机集束搜索。Li 等人[91]
提出在解码过程中，通过计算参考分数，使得来自
于同一个祖先序列的子序列尽量不被同时选中。
还有一些研究直接对候选进行重排序。Yao 等
[92]
人 引入逆文档频率（IDF）对候选进行重排序。
Song 等人[93]提出使用最大边际关联法则（Maximal
Marginal Relevance，MMR）来对候选进行重排序。
引入潜在变量。据对话对象、对话场景等特点

学
机

的关键问题
基于深度学习的开放领域对话系统以数据驱动

报

4 基于深度学习的开放领域对话系统

17

计 算 机 学 报

18

算
计

人对于同一信息可能不同，但是生成式对话模型中
的回复都是从一个确定性的编码器-解码器模型中
采样。一些工作通过引入潜在变量，先对潜在变量
的分布进行采样，再根据分布进行解码，来生成以
潜在变量为根据的回复。
Cao 等人[94]提出一种基于潜在变量的单轮对话
生成模型。该模型在解码器中包含通过变分自编码
器的随机变量 z，模型训练的目标函数变为最大化
条件概率𝑝(𝒓|𝒒, 𝑧)。Serban 等人[82]将潜在变量的方
法引入到层次结构的对话模型中。其潜在变量还可
以有更具体的定义，例如话题或者情感。Shen 等人
[95]
对潜在变量的属性进行明确的条件限制，让这些
属性更具有可解释性。属性可以手动设置也可以自
我学习。Zhou 等人[96]提出编码器-转向器-解码器模
型来模拟对话中的语义的潜在响应机制，使得不同
机制生成不同的回复。Zhao 等人[97]基于条件变分自
编码器模型，以多种语义意图为条件构建对话模
型。
多头注意力机制。Tao 等人[98]应用多头注意力
机制来捕获查询话语中不同方面的语义，并通过正
则化目标函数使得回复包含更多样化且仍与给定
查询更相关。该模型的关键在于构建多个可学习的
投影矩阵，再用点乘的计算方法将编码器 RNN 的
隐藏状态投影到多个不同的语义空间，最后将多头
注意力的语义向量加权求和输入到解码器中，使得
生成的回复更多样。
基于行列式点过程。Song 等人[99]提出两种将行
列式点过程与生成模型结合的方法，来提升生成对
话中查询级别和系统级别两个粒度的多样性

2019 年

意到人们在对话的时候常常把对话跟相关的概念
联系起来，并根据概念形成对话的回复。他们先基
于 LDA 模型学习对话数据的话题，然后将话题信
息和输入表示联合起来作为注意力机制的组件来
生成与话题相关的回复。后来，Xing 等人[102]基于
注意力机制对之前工作 [101] 中的解码器做改进。
Choudhary 等人[103]对话题问题做更加详细的解析，
他们将查询中的每一个词语进行分类，先计算查询
语句的领域，再依次生成回复的内容。
4.3 引入外部知识

学
机

人类交流和对话系统的一个重要区别在于是否
与现实相结合。将外部知识库和对话训练语料相结
合是弥补系统和人类之间背景知识差距的一个方
法。
检索式对话中引入外部知识。匹配模型是检索
式对话系统成功的关键，将外部知识引入到匹配模
型可以增强匹配特征，优化匹配效果。Lowe 等人[104]
提出先用 TFIDF 选择与对话上下文相关的非结构
化文本的外部知识，再通过知识编码器 RNN 进行
知识表示，最后计算候选回复匹配分数时同时考虑
与上下文和外部知识。Young 等人[105]提出将常识知
识图谱存储在外部记忆模块的方法，
采用 Tri-LSTM
模型分别编码查询、回复和常识，将相关常识整合
到检索式对话的匹配模型中。Yang 等人[106]提出将
外部问答知识融合到检索方法的深度匹配模型中。
该方法首先从外部问答知识库中检索与候选回复
相关的问答对作为外部知识来源，然后从中提取关
键信息扩展候选回复，并将扩展后的匹配特征加入
到匹配分数计算，改善上下文和候选回复的匹配效
果。Wu 等人[107]针对语义和句法结构复杂的长文本
的语义匹配问题，提出用先验知识识别长文本中有
用信息并过滤噪音的模型，来增强文本表示，提升
匹配性能。
生成式对话中引入外部知识。生成式对话系统
中通常通过增加与对话上下文相关的知识型语义
表示，为解码器提供更丰富的信息。Zhu 等人[108]
提出的 GenDS 模型，用对话上下文中的实体相关
的事实知识来增强上下文的语义表示。Vougiouklis
等人[109]预先用卷积神经网络对带分类信息的维基
百科语料库训练句子表示模型。在对话系统训练和
预测时，用预训练的句子表示模型计算输入的语义
表示，再与基础序列到序列模型中的解码器 RNN
隐藏向量拼接来解码生成回复。Ghazvininejad 等人
[110]
用记忆网络建立了一个基于知识库回答的开放

话题模型（Topic Model）是在大量文本中发现
抽象话题/主题的一种统计模型。直观来说，文本包
含一定的话题，与这些话题有关的词语会更频繁的
出现。话题模型已经被应用到文本分类等自然语言
处理领域，取得不错的效果。
检索式对话中引入话题线索。Wu 等人[100]提出
用卷积神经网络模型结合话题信息对查询和回复
进行语义表示。具体来说，该模型先用卷积神经网
络将查询和回复表示成句向量，并根据 Twitter 基于
LDA 训练的话题模型计算出其话题加权的向量表
示，再将查询分别与回复和回复话题的向量表示进
行语义融合，回复也与查询及查询话题的向量表示
进行语义融合，实现基于话题的回复选择。
生成式对话中引入话题线索。Xing 等人[101]注

报

4.2 话题控制

陈晨等：基于深度学习的开放领域对话系统研究综述

领域对话生成系统中。其核心思想是先在对话上下
文中找到知识库中的知识，并将知识转换为语义向
量表示与对话上下文向量表示整合输入到解码器
中生成回复。最近，Zhou 等人[111]用注意力机制将
对话生成模型与大规模知识图谱技术相结合。他们
的系统包含三个模块：编码器-解码器模块，知识解
释模块和知识生成模块。知识解释模块采用基于静
态的注意力机制，将词向量和检索到的知识图谱图
形向量连接。知识生成模块采用动态的注意力机
制，根据关注权重来读取图中影响选择生成的词
语。
4.4 融入情感

算
计

“悲你所悲，喜你所喜”，真正的情感抚慰和
陪伴需要融入情感的对话，可以称之为情感智力
（Emotion Intelligence）
。情感智力是成功的、智能
的对话系统不可或缺的重要组成部分。与检索式方
法相比，生成式方法更灵活、更方便融入情感。
基于记忆网络。Zhou 等人[112]首先将情感因素
引入到生成式对话系统，提出基于记忆网络的情感
对话系统（Emotional Chatting Machine，ECM）
。他
们在传统的序列到序列模型的基础上，使用了静态
的情感向量表示、动态的情感状态记忆网络和情感
词外部记忆的机制，使得 ECM 可以根据指定的情
感分类输出对应情感的回复。
基于带情感的词向量。Asghar 等人 [113]针对对
话中的情感问题从以下三方面对序列到序列做改
进： (1)引入带情感信息的词向量。这个词向量共
有三维，每一维度代表情感的一个因素。(2)提出三
个与情感因素相关的损失函数：最小化情感失调，
最大化情感失调、最大化情感内容。(3)在解码时考
虑情感，让解码出来的候选回复的情感尽可能的不
一样，增加多样性。
基于条件变分自编码器。Zhou 等人[114]利用社
交网络 Twitter 数据中的表情符号建立了一个大规
模、有情感标签的对话数据集，训练表情符号的向
量词典，并基于条件变分自编码器构建以表情符号
为条件生成回复的开放领域对话模型。

话人不做区分，所以通用模型不能解决个性化回复
问题。一些研究基于生成式方法研究个性化的对话
模型。
融入个性化向量表示。Zhang 等人[115]首先使用
通用数据集训练得到对话生成模型，再利用包含用
户信息的数据集调整模型，使得生成的回复具有个
性化的背景信息。模型中的用户信息由向量表示。
Li 等人[116]探索了两种个性化对话模型：（1）一元
说话者模型：将说话者信息表示向量整合输入到模
型中；
（2）二元说话者模型：将说话者和说话对象
信息表示合并，看作交流模型的向量表示。与之前
的工作不同，Engonopoulos 等人[117]认为人工定义
的用户分组无法反映数据的真实特性也不能高效
的扩展新用户，因此引入在训练对话模型的过程中
同时训练出的用户组特征信息的模型，使得系统能
够根据不同用户自动产生相应的回复。
基于双向解码器模型。Qian 等人[118]在生成回
复时结合用户的个人资料信息。其主要思想是，存
储与用户相关的属性键值对，给定查询先用注意力
机制探测是否包含属性键，如果包含则以其对应属
性值为起点分别向前向后解码，生成包含确定属性
值的回复。

学
机

人在说话的时候有个性化的偏好，且对话语的
理解能力也因为年龄、认知及其他因素的影响而各
不相同。有效的对话系统应该主动适应当前用户，
给出适合他们的回复。当前，大多数训练数据集包
含不同人的对话，但是基本的对话模型对于不同说

4.6 主动对话

标准的对话系统假定只有人类会主动的提出话
题参与聊天，计算机只需要根据人类话语给出回
复，这样的过程是“被动的”[119]。智能的对话系统
应该具备根据对话场景调整对话内容或者主动引
入新信息的能力，尤其是当对话陷入僵局时，系统
应主动提出新话题打破尴尬。
检索式对话系统中的主动建议。Li 等人[119]提出
的 StalemateBreaker 主动对话系统，能够在恰当的
时候主动引导新内容新话题。具体说来，系统从“何
时引导”、
“引导什么”及“如何引导”三方面进行
探索，首先是发现用户认为当前话题无趣的时刻，
接着通过挖掘知识图谱寻找可以引导的新话题，并
从语料库中检索出候选回复，最后用一个排序算法
算出最佳回复。Yan 等人[120]受到传统信息检索系统
中查询建议的启发，提出对话建议的思路。具体来
说，该方法将回复排序和建议排序联合学习，使得
检索出的回复不但能回应当前查询，还能够积极的
引导下一轮对话。
生成式对话系统中的内容引入。基本的生成式
对话系统倾向于生成通用回复。一些研究者提出用
主动内容引入的方式来生成对话。其中有两个关键

报

4.5 个性化回复

19

计 算 机 学 报

20

技术点：一是通过门控机制来修改神经网络中的神
经单元[121, 122] 实现在生成过程中加入额外的线索
词；二是回复中线索词的体现方式包括显式和隐式
两种：显式方式是指在回复话语中明确包含线索
词；隐式方式是指将线索词的语义隐含地包含在回
复话语中。Mou 等人[123]提出的 Seq2BF 模型先预测
关键词并从关键词开始生成回复，由于模型要求关
键词必须出现在回复语句中，故称为显示内容引
入。Yao 等人[124]认为通常回复语句中只要表达出线
索词的语义信息即可，提出隐式的内容引入方法，
利用层次型融合单元来灵活地加入额外地线索词
信息。两者相比，显示的方式比较死板，隐式的方
式更灵活但存在不可控的风险。
4.7 交互对话

算
计

真实的对话是交互式的，让对话系统具备更强
的交互能力也是系统成功的关键。在线交互能力有
两个可努力的方向：一是收集用户反馈，改进对话
回复模型；另一个是学会提问增强系统交互性。
基于在线反馈。Asghar 等人[125]提出在线反馈
对话模型分两阶段训练：一是离线阶段的监督学
习，二是在线交互时的主动学习。在线主动学习的
思路是，先跟据离线模型生成 k 个回复，用户从中
选出一个或提交第 k+1 个作为最佳回复，系统根据
用户选择来优化回复生成模型。Li 等人[126]尝试用
在线方式收集并量化人类在对话中的真实反馈，在

2019 年

交互中提高系统生成回复的能力。
基于在线提问。Li 等人[127]针对对话交互过程
中系统容易出现的三类错误分别给出在线提问的
解决方案：
（1）当系统接收的查询存在拼写错误等
情况时，主动提出让用户确认该错误的问题；
（2）
当系统无法进行知识推理时，主动请求用户给出相
关知识或者验证知识；（3）当系统中知识不完整，
如实体缺失，则应该需要请求用户给出这部分的知
识并保存。

5 开放领域对话系统的评测

学
机

对话系统的质量需要有合理的度量标准来评
价。好的评价标准能指引系统发展的方向，把握技
术的进展。任务导向的对话系统可以根据人工给定
的有监督信号来进行评估，例如任务完成测试 [17]
等。但是开放领域对话系统的回复具有多样性等特
点，自动评估仍然是尚未解决的问题。一般来说，
性能良好的开放领域对话系统需要具备语义相关
度高、信息量丰富、表达方式多样的特点。具体到
不同的实现方法，评测考量指标也有差异，下面分
类进行介绍。
当前开放领域对话系统的评价方法有两种思
路，一种是人工评测，一种是客观地自动评价指标。
详细分类如图 28 所示。

人工评测
开放领域对话系统评测

检索式对话评价指标

不可学习的评测方法

报

自动评测

生成式对话评价指标

监督学习的评测方法

可学习的评测方法

对抗学习的评测方法

图 28 开放领域对话系统评测方法分类

5.1 人工评测
人工评测是指通过测试人员人工对测试结果
进行评测。
三级评分指标。一些研究采用三级人工评测的
方法[25, 72, 101]。该方法邀请多个评测者对生成的测
试回复进行打分，根据回复质量分为三级：+2，表
示与对话上文相比回复语句很自然且语义相关；
+1，回复可以是查询正确的回应，但是包含的信息
非常少。例如“我不知道”，“我不确定”等；0，

回应无关紧要，无意义，或者有严重的语法错误。
成对对比指标。该方法直接将两个模型的回复
作比较选择更好的一个[82]。Chen 等人[85]要求打分
者从回复的恰当性和包含的信息量两个维度分别
选出表现更好的一个。
5.2 不可学习的评测指标
5.2.1 检索模型评测指标
在检索式对话系统中，候选答案的排序是这类
系统的核心，一般使用传统信息检索系统的常用评

陈晨等：基于深度学习的开放领域对话系统研究综述

测 指标。 早期包 括准确率 （ Precision ）、召 回率
（Recall）
、F1 值等。
 召回率=系统检索到的相关回复/系统所有相关
的回复总数
 准确率=系统检索到的相关回复/系统所有检索
到的回复总数
召回率考察系统找全回复的能力，而准确率考
察系统找准回复的能力，两者相辅相成，从两个不
同侧面较为全面地反映系统性能。F1 值是召回率和
准确率的调和平均数。
𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 ∙𝑟𝑒𝑐𝑎𝑙𝑙

F1 = 2 𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 +𝑟𝑒𝑐𝑎𝑙𝑙

(1)

算
计

随着测试集规模的扩大以及人们对评测结果理
解的深入，研究者提出能更准确反映系统性能的新
评价指标，包括：
 平均准确率（Mean Average Precision，即 MAP）:
AP（Average Precision）是指单个查询检索的
平均精确度，MAP 是对整个测试集求平均 AP
值。
1

MAP = |𝑄

𝑅|



𝑞∈𝑄𝑅

𝐴𝑃 𝑞

(2)

量对话生成效果，认为生成长句子的模型相对
质量更高。
（2）
基于词语重叠的方法

BLEU 指标[128]：根据 n 元词 𝑛 = 1, … ,4 的准
确率计算几何平均来衡量生成回复与真实回
复的相似度。这个指标最早是在机器翻译任务
中使用，Serban 等人[21]等都用到它来对生成式
对话系统进行评分。然而，它的有效性受到
Galley 等人[129]的质疑并提出了可以考虑多个
回复的 deltaBLEU 指标，然而现实中很难获得
多个参考回复。

ROUGE 指标[130]：是一种衡量 N-gram 的召回
率的评测方法，也是基于词语重叠程度来衡量
生成语句的质量，主要用于文本摘要任务的评
测。与 N-gram 不同，ROUGE 指标中的子串不
必连续。它基于生成回复和真实回复的最长公
共子序列的召回率计算。最长公共子序列是指
在两句话中都按相同次序出现的一组词序列。

METEOR 指标[131]：该指标加入了生成回复和
真实回复之间的对齐关系。使用 WordNet 计算
特定的序列匹配、同义词、词根、词缀、释义
之间的匹配关系，改善 BLEU 效果，使其跟人
工判别共更强的相关性。同样也是使用
F-measure 的计算方法。
尽管 BLEU、METEOR、ROUGE 等词汇重叠
评测方法已经被广泛的应用到生成式对话系统，但
是 Liu 等人[132]发现，这些评测方法仍然跟人类判断
之间的相关性很弱。相比之下，BLEU 指标的效果
要好于 ROUGE 和 METEOR，但也仅限于在 Twitter
语料库上表现出与人类判断之间很弱的相关性，在
技术领域 Ubuntu 对话语料库则几乎没有相关性。
其中，BLEU-2 指标的效果要好于 BLEU-3/4。
（3）
基于词向量的方法
上面的词重叠评价指标基本上都是用 N-gram
计算生成回复和真实回复之间的重合程度。而 Liu
等 人 [132] 提 出 了 基 于 词 向 量 的 评 价 指 标 ， 通 过
Word2Vec、Sent2Vec 等方法将句子转换为语义向量
表示，再通过余弦相似度等方法就计算生成回复和
真实回复之间的语义相似程度。相比词重叠要求出
现完全相同 N-gram 的条件，词向量方法的限制降
低很多，可以基于词向量计算大多数词语对相似
度，再设计算法计算生成回复和参考回复之间的相
似性。后来一些研究使到该指标进行评测[85]。

贪婪匹配（Greedy Matching）：如公式（3）

学
机

R-Precision：单个查询的 R-Precision 是检索出
R 个回复时的准确率。其中 R 是测试集中与查
询相关的回复。
 P@10：是系统对于该查询返回的前 10 个结果
的准确率。
5.2.2 生成模型评测指标
（1）
不需要参考回复的评测指标

困惑度（Perplexity） [27]：语言模型中通常用
困惑度来衡量一句话出现的概率，也常常被用
在对话生成评测中，评价生成回复语句的语言
质量。其基本思想是测试生成的回复语言质量
越高，困惑度越小，越接近人类正常说话，模
型越好。困惑度指标的缺点是不能评估在对话
中回复与上文的相关性。

熵（Entropy）：熵可以度量生成的回复的信息
量[82, 123]。

回复多样性指标 Distinct-1&2：针对对话系统
中万能回复的问题，Li 等人[88]提出通过计算生
成回复中 1 元词和 2 元词的比例来衡量回复的
多样性。具体来说，Distinct-1 和 Distinct-2 分
别是不同的 unigrams 和 bigrams 的数量除以生
成的单词总数。

平均回复长度：文献[81, 123]用平均长度来衡

21

报

计 算 机 学 报

22

和公式（4）所示，对于真实回复的每个词，
寻找其在生成回复中词向量相似度最高的词，
并将其余弦相似度相加并求平均。同样再对生
成回复再做一遍，并取二者的平均值。该指标
主要关注两句话之间最相似的词语。
G 𝒓, 𝒓 =

𝑤 ∈𝑟 max𝑤 ∈𝑟

𝐺 𝒓,𝒓 +𝐺 𝐫,𝐫

(4)

2

平均匹配（Embedding Average）：这种方法直
接使用句向量计算真实回复和生成回复之间
的余弦相似度。句向量是句子包含的词向量的
加和平均，如公式（5）和（6）所示。
e𝒓 =

𝑤 ∈𝒓 𝑒𝑤
′
𝑤 ′ ∈𝒓 𝑒𝑤

(5)

算
计



(3)

|𝑟|

GM 𝒓, 𝒓 =



cos ⁡_𝑠𝑖𝑚 (𝑒𝑤 ,𝑒 𝑤 )

EA ∶= cos⁡
(e𝒓 , e𝒓 )
(6)
向量极值（Vector Extrema）：这种方法需获取
向量的极值。具体来说，对于词向量的每一个
维度，取其最大值和最小值来作为句子向量的
该维度表示，详见公式（7）
。
𝑚𝑎𝑥 𝑤∈𝒓 𝑒𝑤𝑑 𝑖𝑓 𝑒𝑤𝑑 > |𝑚𝑖𝑛𝑤′∈𝑟 𝑒𝑤′𝑑 |
𝑚𝑖𝑛 𝑤 ∈𝒓 𝑒𝑤𝑑
𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒

M 和 N 可以理解为将上下文 c 和参考回复 r 投
影到可与生成回复𝒓直接比较的表示空间，最
终的目的是训练出 M 和 N，目标函数是使得模
型预测得分与人类评分的误差最小。ADEM 评
价模型需要大量的人工标注的分数作为训练
数据，因此不宜扩展。
(8)
score 𝑐, 𝑟, 𝑟 = (𝑐 𝑇 𝑀𝑟 + 𝑟 𝑇 𝑁𝑟 − 𝛼) 𝛽
[134]

RUBER ：RUBER 指标也是基于监督式学
习的方法，同样结合对话上下文和参考回复建
立评价模型。具体来说，该方法将有参考的指
标和无参考的指标想结合来评价对话回复：有
参考的指标指通过词向量来计算回复和真实
回复之间的相似度；无参考的指标用最大边际
目标函数训练回复和查询之间的相关性。与
ADEM 相比，RUBER 评价指标的训练不需要
人工评价标签，更为灵活并且易于扩展到不同
的数据集和语言。RUBER 在检索和生成式对
话系统上都进行了实验，结果表明 RUBER 与
人工评价具有很高的相关性。
5.3.2 对抗学习
最早将对抗学习的思想用于自然语言处理技
术评估是 Bowman 等人[135]，他们训练一个判别器
来区分系统生成的句子和真实句子。借用图灵测试
的思路，Kannan 等人[136]在生成式对话系统中初步
研究对抗评估的方法。其主要思路是训练评估系统
来代替人工评估员来区分人类回复和系统生成回
复，再用这个评估系统来评估生成回复的质量。Xu
等人 [76] 在基于生成对抗网络建立对话系统模型时
也建立了一个回复质量的判别器。Tong 等人[137]对
监督学习的 RUBER 指标做改进，基于对抗性的多
任务学习框架建立了一个多语言对话的评估模型，
使得不同的语言可以同时建立评估模型，并促进跨
语言的知识共享。

学
机

𝑒𝑟𝑑 =

2019 年

5.3 可学习的评测指标
不可学习的评测方法仅利用生成回复自身的
特征或信息量来进行评测，没有结合对话上下文语
境。最近，一些研究针对对话系统提出监督学习的
评测方法，训练神经网络评价模型来实现对开放领
域对话系统的评价。
5.3.1 监督学习
ADEM[133] ：该方法需预先收集对话语料的人
工评分，并使用层次循环神经网络训练自动对
话评估模型，目标是预测人工评分。计算评分
的公式如公式（8）
，其中，c 是对话上下文的
向量表示，r 是参考回复的向量表示，𝒓是模型
生成回复的向量表示。M 和 N 是参数矩阵，
和 β 是在 0,5 范围内初始化的标量常量。矩阵

报

(7)
其中，d 是向量的维度； ewd 表示 w 的词向量
ew 的第 d 维的值。由于词向量值可能是正也可
能是负的，公式中的 min 函数意思就是，如果
最小负值的绝对值大于最大的正值时，则取负
值。通过沿着每个维度取极值，可以忽略常见
词汇，重要语义信息的词会保留。

6 基于深度学习的开放领域对话系统
研究趋势展望
随着技术的发展，深度学习在自然语言处理领
域被越来越多地研究，基于深度学习的开放领域对
话系统已经成为当前的研究热点。但是，由于研究
时间较短，深度学习技术在开放领域对话系统中的
应用尚处于起步阶段，检索式方法和生成式方法都
还不能模拟或者代替人类对话，许多关键性问题值

陈晨等：基于深度学习的开放领域对话系统研究综述

算
计

得深入探索。本文总结以下七个研究方向。
（1）基于深度学习提高开放领域对话系统的
情感拟人程度。数据驱动的开放领域对话系统着重
关注建立查询和回复的语义对应关系。而现实中，
人类真实对话还会受到情感等方面的影响，虽然目
前已有相关研究出现，但是拟人程度还远远不够。
深度学习技术在情感分析领域已经取得了一定成
果，可以将其引入来精准识别用户情绪（积极正面、
消极负面等），并根据不同的情感类型给出相应拟
人的回应。例如，当输入查询的情绪为消极负面情
绪时，系统给出安抚回复，当话题陷入沉闷无趣时，
则给出具有幽默感和有趣的回复。还可以探索基于
强化学习框架建立带在线反馈机制的交互式情感
引导对话模型。总的来说，基于深度学习模型来实
现情感拟人程度更高的开放领域对话系统将是未
来可研究的方向。
（2）基于深度学习控制开放领域对话系统的回
复逻辑。对话逻辑问题是目前对话系统实现的难
点。一方面人类对话常常包含常识的推理和演绎，
目前的系统尚未对其建模。另一方面，数据驱动的
开放领域对话系统以对话语料库为基础给出查询
概率最大的回复，无法保证回复逻辑一致。这个问
题在生成式开放领域对话系统中尤其突出。当前，
基于深度学习技术的阅读理解任务已对文本内容
推理过程建模，取得了初步研究成果。未来，可以
尝试用深度学习技术对对话逻辑推理建模，并整合
到根据查询输出回复的过程中。
（3）基于深度学习主动把握开放领域对话系统
的对话节奏。当前的开放领域对话系统以被动的回
应为主。而真实的对话场景下，对话节奏通常由对
话双方共同把握。虽然已有一些研究尝试通过对话
建议和内容引导的方式，引入新的内容，但还远不
能满足把握对话节奏的要求。未来，可以继续研究
基于深度学习技术的内容引导和节奏把控方法。一
方面，可以考虑将当前的一步式引导拓展到多步引
导，以更加平缓的方式引导新内容，使得对话节奏
转换更加自然。另一方面，可以在内容引导的框架
下探索考虑对话双方的互动，预测对话趋势，更有
效的掌控对话节奏。
（4）基于深度学习建立更合理的对话评价机
制。合理的开放领域对话系统的评价指标对于持续
提升系统性能至关重要，能让研究工作目标明确，
并有针对性地设计技术方案进行改进。检索式对话
系统通常假设只有一个正确的回复，即使给出的回

23

学
机

复与正确回复相似也会被视为是错误回复。尤其在
多轮对话的评测中，完全匹配的限制过于严格，不
符合对话实际。生成式对话系统则主要延续机器翻
译的评测方法，即通过计算系统生成回复和参考回
复之间的差距来衡量生成回复的质量。然而，对话
系统和机器翻译不一样，由于对话的多样性特点，
单凭一个或有限个标准回复去衡量生成回复的设
定不充分也不合理。还有很多工作通过人工评测来
进行效果评价，代价大且不易标准化。目前已有一
些基于监督学习的评价系统，但其通用性或者与人
工评价的相关性仍有待改进。未来应继续深入研究
开放领域对话系统的评测方法，探索更先进的深度
学习模型，建立更合理的评测机制。
（5）通过深度学习模型将检索式和生成式方法
更好的整合。检索式和生成式对话模型原理不同，
实现技术不同，各有优缺点，却有相同的目标。检
索式方法能给出更流畅的、更符合逻辑的回复。生
成式则能够对更复杂的语境建模，例如情感、个性
化等。现在已经少数研究将两种方法相结合，提升
对话整体效果。未来，随着深度学习技术的发展，
可以尝试研究更多的组合机制，相信会给开放领域
对话系统带来更大的突破。
（6）使用数据增强技术构建高质量的基准对话
数据集。对于深度学习模型来讲，训练数据的不断
增加能够带来性能的提升。然而，在开放领域对话
系统中，对话数据集大多从社交网络中收集，不可
避免地存在大量错误和噪音，高质量的对话数据相
对缺乏。数据增强技术已经在图像处理领域取成
功，在自然语言处理领域还没有被深入探索。研究
自然语言的数据增强技术，将其应用到开放领域对
话系统中，构造优质、大规模的基准对话数据集是
未来可以努力的方向。
（7）使用深度学习技术构建多模态的开放领域
对话系统。现实中，社交网络的人人对话常常混合
使用各种类型的数据进行交互，即语音、图像、文
本常常混合使用。当前，深度学习技术在语音、图
像、文本单独领域的应用研究较多，取得了一定的
成果，但将这些技术综合应用的多模态技术还有待
深入研究。为了将对话系统投入实际使用，发挥有
效价值，建立基于多模态的开放领域对话系统也是
当前工业界关注的方向。

报

计 算 机 学 报

24

Botelho W.T., Pimentel E., França R.D.S., Silva V.L.D.

7 结束语

Artificial intelligence markup language: A brief tutorial.

人机对话系统作为下一代人机交互的服务模
式，受到工业界和学术界的广泛关注。深度学习技
术的发展和对话数据在互联网上的积累，也为数据
驱动的开放领域对话系统带来了机遇。根据是否考
虑历史对话信息，开放领域对话系统分为单轮对话
系统和多轮对话系统。根据系统实现方法，基于深
度学习的开放领域对话系统可分为检索式模型、生
成式模型及二者相结合的模型。本文主要围绕基于
深度学习技术的开放领域对话系统进行介绍，分类
梳理已有的研究成果，整理关键问题及已有的解决
方案，总结开放领域对话系统的评测指标，尝试为
研究人员建立一个较完整的领域研究视图，希望能
对相关领域的研究者提供帮助。

算
计

致 谢 在此，我们向对本文的工作给予支持和建
议的同行表示衷心的感谢！

参 考 文 献

Turing A.M. I.—computing machinery and intelligence.
Mind, 1950, LIX (236): 433-460

[2]

Yan R. " Chitty-chitty-chat bot": Deep learning for
conversational AI//Proceedings of the International Joint
Conference

on

Artificial

Sweden, 2018: 5520-5526

Stockholm,

Chen H., Liu X., Yin D., Tang J. A survey on dialogue

systems: Recent advances and new frontiers. ACM
Special Interest Group on Knowledge Discovery and
Data Mining (SIGKDD) Explorations, 2017, 19(2): 25-35
[4]

Weizenbaum J. Eliza — a computer program for the
study of natural language communication between man
and machine. Communications of The ACM, 1966, 9(1):
36-45

[5]

Wilensky R., Chin D.N., Luria M., Martin J.H., Mayfield
J., Wu D. The berkeley unix consultant project.
Computational Linguistics, 1988, 14(4): 35-84

[6]

Wallace R.S. The Anatomy of A.L.I.C.E//Epstein R,
Roberts G,

Beber G.

Parsing the Turing Test:

Philosophical and Methodological Issues in the Quest for
the Thinking Computer. Netherlands: Springer, 2009:
181-210
[7]

[8]

Nakano M., Miyazaki N., Yasuda N., Sugiyama A.,
Hirasawa J., Dohsaka K., Aikawa K. Wit: A toolkit for
building

robust

and

real-time

spoken

dialogu

systems//Proceedings of the Annual Meeting of the
Special Interest Group on Discourse and Dialogue. Hong
Kong, China, 2000: 150-159
[9]

Leuski A., Traum D.R. Npceditor: Creating virtual human
dialogue

using

information

retrieval

techniques.

Innovative Applications of Artificial Intelligence, 2011,
32(2): 42-56
[10] Serban I.V., Lowe R., Henderson P., Charlin L., Pineau J.
A survey of available corpora for building data-driven
dialogue systems. arXiv preprint arXiv:1512.05742, 2015
[11] Serban I.V., Lowe R., Charlin L., Pineau J. Generative
deep neural networks for dialogue: A short review. arXiv
preprint arXiv:1611.06216, 2016
[12] Shang L., Lu Z., Li H. Neural responding machine for
short-text conversation//Proceedings of the International
Joint Conference on Natural Language Processing.

Marietto M.D.G.B., De Aguiar R.V., Barbosa G.D.O.,

Beijing, China, 2015: 1577-1586

[13] Zhang W., Zhang Y. Liu T. Survey of evaluation methods
for dialogue systems. Science China: Scientia Sinica
information, 2017(47)8: 953-966
( 张伟男, 张杨子, 刘挺. 对话系统评价方法综述. 中

国科学:信息科学, 2017(47)8: 953-966)

报

[3]

Intelligence.

arXiv preprint arXiv: 1307.3091, 2013

学
机

[1]

2019 年

[14] Luong T., Pham H., Manning C.D. Effective approaches
to

attention-based

neural

machine

translation//Proceedings of the Empirical Methods in
Natural Language Processing. Lisbon, Portugal, 2015:
1412-1421
[15] Godfrey J.J., Holliman E., Mcdaniel J. Switchboard:
Telephone

speech

corpus

development//Proceedings

for

of

research

the

and

International

Conference on Acoustics, Speech, and Signal Processing,
San Francisco, USA, 1992: 517-520
[16] Kim S., Dharo L.F., Banchs R.E., Williams J.D.,
Henderson M., Yoshino K. The fifth dialog state tracking
challenge//Proceedings

of

the

Spoken

Language

Technology Workshop. San Diego, USA, 2016: 511-517
[17] Kim S., D’Haro L.F., Banchs R.E., Williams J.D.,
Henderson M. The fourth dialog state tracking challenge.

陈晨等：基于深度学习的开放领域对话系统研究综述

[27] Bengio Y., Ducharme R., Vincent P., Janvin C. A neural

AI Magazine, 2017, 35(4): 121-124
[18] Danescuniculescumizil C., Lee L. Chameleons in
imagined

conversations:

understanding

A

coordination

25

new

of

approach

linguistic

style

to

probabilistic language model. Journal of Machine
Learning Research, 2003, 3(6): 1137-1155

in

[28] Rumelhart D.E., Hinton G.E., Williams R.J. Learning

dialogs//Proceedings of the Meeting of the Association

representations by back-propagating errors. Nature, 1988,

for Computational Linguistics, Portland, USA, 2011:

323(6088): 696-699
[29] Hinton G.E., Osindero S., Teh Y.W. A fast learning

76-87
[19] Tiedemann J. News from OPUS-A collection of
multilingual parallel corpora with tools and interfaces.
Recent Advances in Natural Language Processing, 2009,
5: 237-248

algorithm for deep belief nets. Neural Computation,
2006, 18(7): 1527-1554
[30] Bengio Y., Lamblin P., Popovici D., Larochelle H. Greedy
layer-wise training of deep networks//Proceedings of the

[20] Ritter A., Cherry C., Dolan B. Unsupervised modeling of
twitter conversations//Proceedings of the North American
Chapter of the Association for Computational Linguistics.
Los Angeles, USA, 2010: 172-180

Neural Information Processing Systems. Vancouver,
Canada, 2006: 153-160
[31] Doersch C. Tutorial on variational autoencoders. arXiv
preprint arXiv:1606.05908, 2016
[32] Hu B., Lu Z., Li H., Chen Q. Convolutional neural

Mitchell M., Nie J., Gao J., Dolan B. A neural network

network architectures for matching natural language

approach

sentences//Proceedings

to

算
计

[21] Sordoni A., Galley M., Auli M., Brockett C., Ji Y.,

context-sensitive

generation

of

conversational responses//Proceedings of the North
American Chapter of the Association for Computational
Linguistics. Denver, USA, 2015: 196-205

[22] Higashinaka R., Kobayashi N., Hirano T., Miyazaki C.,

of

the

Neural

Information

Processing Systems. Montreal, Canada, 2014: 2042-2050
[33] Kim Y. Convolutional neural networks for sentence
classification. arXiv preprint arXiv:1408.5882, 2014
[34] Lipton Z.C. A critical review of recurrent neural networks

学
机

Meguro T., Makino T., Matsuo Y. Syntactic filtering and

for sequence learning. arXiv preprint arXiv:1506.00019,

content-based retrieval of twitter sentences for the

2015

generation of system utterances in dialogue systems.
Situated

dialog

in

interaction//Situated

speech-based
Dialog

in

human-computer
Speech-Based

[35] Hochreiter S. Schmidhuber J. Long short-term memory.
Neural Computation, 1997, 9(8): 1735-1780

[36] Cho K., Van Merrienboer B., Bahdanau D., Bengio Y. On

Human-Computer Interaction. Springer International

the

Publishing, Cham, 2016: 15-26

Encoder-decoder

multiparticipant chat analysis. 2013 National Conference
on Artificial Intelligence (AAAI) Spring Symposium
Series: Analyzing Microtext, 2013
[24] Lowe R., Pow N., Serban I.V., Pineau J. The ubuntu

of

neural

machine

报

[23] Uthus D.C., Aha D.W. The ubuntu chat corpus for

properties

approaches//Proceedings

translation:
of

the

Empirical Methods in Natural Language Processing.
Doha, Qatar, 2014: 103-111
[37] Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D.,
Bougares F., Schwenk H., Bengio Y. Learning phrase
representations using RNN encoder-decoder for statistical

dialogue corpus: A large dataset for research in

machine

unstructured multi-turn dialogue systems//Proceedings of

Methods in Natural Language Processing. Doha, Qatar,

the Annual Meeting of the Special Interest Group on

2014: 1724-1734

Discourse and Dialogue. Prague, Czech Republic, 2015:
285-294
[25] Song Y., Yan R., Li X., Zhao D., Zhang M. Two are better
than one: An ensemble of retrieval- and generation-based
dialog systems. arXiv preprint arXiv:1610.07149, 2016
[26] LeCun Y., Bengio Y., Hinton G. Deep learning. Nature,
2015, 521(7553): 436.

translation//Proceedings

of

the

Empirical

[38] Sutskever I., Vinyals O., Le Q.V. Sequence to sequence
learning with neural networks//Proceedings of the Neural
Information Processing Systems. Montreal, Canada,
2014: 3104-3112
[39] Bahdanau D., Cho K., Bengio Y. Neural machine
translation by jointly learning to align and translate. arXiv
preprint arXiv:1409.0473, 2014

计 算 机 学 报

26

[40] Vaswani A., Shazeer N., Parmar N., Jones L., Uszkoreit

2019 年

[51] Yin W., Schutze H., Xiang B., Zhou B. Abcnn:

J., Gomez A.N., Kaiser Ł. Attention is all you

Attention-based

need//Proceedings of the Neural Information Processing

modeling sentence pairs. Transactions of the Association

Systems. Long Beach, USA, 2017: 5998-6008

for Computational Linguistics, 2016, 4: 259-272

[41] Weston J., Chopra S., Bordes A. Memory networks. arXiv
preprint arXiv:1410.3916, 2014

memory networks//Proceedings of the Neural Information

neural

network

for

[52] Kim S., Hong J.H., Kang I., Kwak N. Semantic sentence
matching

[42] Sukhbaatar S., Szlam A., Weston J., Fergus R. End-to-end

convolutional

with

co-attentive

densely-connected
information.

recurrent

arXiv

and

preprint

arXiv:1805.11360, 2018

Processing Systems. Montreal, Canada, 2015: 2440-2448

[53] Lu Z., Li H. A deep architecture for matching short

[43] Goodfellow I.J., Pougetabadie J., Mirza M., Xu B.,

texts//Proceedings of the Neural Information Processing

Wardefarley D., Ozair S., Courville A.C., Bengio Y.

Systems. Lake Tahoe, USA, 2013: 1367-1375

Generative adversarial nets//Proceedings of the Neural

[54] Pang L., Lan Y., Guo J., Xu J., Wan S., Cheng X. Text

Information Processing Systems. Montreal, Canada,

matching as image recognition//Proceedings of the

2014: 2672-2680

National Conference on Artificial Intelligence. Phoenix,

[44] Sutton R.S. Barto A.G. Introduction to reinforcement

算
计

learning. MIT Press, 1998

USA, 2016: 2793-2799
[55] Liu P., Qiu X., Chen J., Huang X. Deep fusion lstms for

[45] Mnih V., Kavukcuoglu K., Silver D., Graves A.,

text semantic matching//Proceedings of the Meeting of

Antonoglou I., Wierstra D., Riedmiller M.A.J.a.L.

the Association for Computational Linguistics. Berlin,

Playing atari with deep reinforcement learning. arXiv

Germany, 2016: 1034-1043

preprint arXiv:1312.5602, 2013

[46] Sutton R.S., Mcallester D.A., Singh S.P., Mansour Y.
Policy gradient methods for reinforcement learning with

[56] Wang

Z.,

Hamza

multi-perspective

W.,

matching

for

R.

Bilateral

natural

language

sentences// Proceedings of the International Joint

学
机

function approximation//Proceedings of the Neural

Conference

Information Processing Systems. Denver, USA, 1999:

Australia, 2017: 4144-4150

1057-1063

Florian

on

Artificial

Intelligence.

Melbourne,

[57] Wan S., Lan Y., Xu J., Guo J., Pang L., Cheng X.
Match-srnn: Modeling the recursive matching structure

matching model for ad-hoc retrieval//Proceedings of the

with spatial rnn//Proceedings of the International Joint

International Conference on Information and Knowledge

Conference on Artificial Intelligence. New York, USA,

Management, Indianapolis, IN, USA, 2016: 55-64

2016: 2922-2928

报

[47] Guo J., Fan Y., Ai Q., Croft W.B. A deep relevance

[48] Shen Y., He X., Gao J., Deng L., Mesnil G. Learning

[58] Mitra B., Diaz F., Craswell N. Learning to match using

semantic representations using convolutional neural

local and distributed representations of text for web

networks for web search//Proceedings of the International

search// Proceedings of the International World Wide

World Wide Web Conferences. Seoul, Korea, 2014:

Web Conferences. Perth, Australia, 2017: 1291-1299
[59] Yu J., Qiu M., Jiang J., Huang J., Song S., Chu W., Chen

373-374
[49] Wan S., Lan Y., Guo J., Xu J., Pang L., Cheng X. A deep

H. Modelling domain relationships for transfer learning

multiple

on retrieval-based question answering systems in

positional sentence representations//Proceedings of the

e-commerce//Proceedings of the Web Search and Data

National Conference on Artificial Intelligence. Phoenix,

Mining. Marina Del Rey, USA, 2018: 682-690

architecture for semantic

matching with

USA, 2016: 2835-2841

[60] Huang G., Liu Z., Der Maaten L.V., Weinberger K.Q.

[50] Tan M., Santos C.N.D., Xiang B., Zhou B. Improved

Densely connected convolutional networks//Proceedings

representation learning for question answer matching//

of the IEEE Conference on Computer Vision and Pattern

Proceedings of the Meeting of the Association for
Computational Linguistics. Berlin, Germany, 2016:
464-473

Recognition. Honolulu, USA, 2017: 2261-2269
[61] Inaba M. Takahashi K. Neural utterance ranking model
for conversational dialogue systems//Proceedings of the

陈晨等：基于深度学习的开放领域对话系统研究综述

27

Annual Meeting of the Special Interest Group on

conversation

Discourse and Dialogue. Los Angeles, USA, 2016:

models// Proceedings of the Empirical Methods in

393-403

Natural Language Processing. Copenhagen, Denmark,

[62] Zhou X., Dong D., Wu H., Zhao S., Yu D., Tian H., Liu
X.,

Yan

R.

Multi-view

selection

with

sequence-to-sequence

2017: 2210-2219

for

[71] Wang W., Huang M., Xu X., Shen F., Nie L. Chat more:

the

Deepening and widening the chatting topic via a deep

Empirical Methods in Natural Language Processing.

model//Proceedings of the International ACM SIGIR

Austin, Texas, USA, 2016: 372-381

Conference on Research and Development in Information

human-computer

response

responses

conversation//Proceedings

of

[63] Yan R., Song Y., Wu H. Learning to respond with deep

Retrieval. Ann Arbor, USA, 2018: 255-264

neural networks for retrieval-based human-computer

[72] Wu Y., Wu W., Li Z., Xu C., Yang D. Neural response

conversation system//Proceedings of the International

generation with dynamic vocabularies//Proceedings of the

ACM SIGIR Conference on Research and Development

National Conference on Artificial Intelligence. New

in Information Retrieval. Pisa, Italy, 2016: 55-64

Orleans, USA, 2018: 5594-5601

[64] Wu Y., Wu W., Xing C., Zhou M., Li Z. Sequential

[73] Shang M., Fu Z., Peng N., Feng Y., Zhao D., Yan R.

matching network: A new architecture for multi-turn

Learning to converse with noisy data: Generation with

response

calibration//Proceedings

in

retrieval-based

chatbots//

算
计

selection

of

Proceedings of the Meeting of the Association for

Conference

Computational Linguistics. Vancouver, Canada, 2017:

Sweden, 2018: 4338-4344

496-505

on

Artificial

the

International

Intelligence.

Joint

Stockholm,

[74] Mei H., Bansal M., Walter M.R. Coherent dialogue with

[65] Zhang Z., Li J., Zhu P., Zhao H., Liu G. Modeling

attention-based language models//Proceedings of the

multi-turn conversation with deep utterance aggregation//

National Conference on Artificial Intelligence. Phoenix,

Proceedings

of

the

International

Conference

on

3740-3752

USA, 2016: 3252-3258

学
机

Computational Linguistics. Santa Fe, USA, 2018:

[75] Li J., Monroe W., Ritter A., Jurafsky D., Galley M., Gao
J. Deep reinforcement learning for dialogue generation//

[66] Zhou X., Li L., Dong D., Liu Y., Chen Y., Zhao W.X., Yu

Proceedings of the Empirical Methods in Natural

D., Wu H. Multi-turn response selection for chatbots with

Language Processing. Austin, USA, 2016: 1192-1202

deep attention matching network//Proceedings of the

[76] Li J., Monroe W., Shi T., Jean S., Ritter A., Jurafsky D.

Meeting

of

the

Association

for

Computational

Adversarial learning for neural dialogue generation//

报

Linguistics. Melbourne, Australia, 2018: 1118-1127

Proceedings of the Empirical Methods in Natural

[67] Yan R., Song Y., Zhou X., Wu H. "Shall I be your chat

Language Processing. Copenhagen, Denmark, 2017:

companion?":

Towards an

online human-computer

2157-2169

conversation system// Proceedings of the International

[77] Xu Z., Liu B., Wang B., Sun C., Wang X., Wang Z., Qi C.

Conference on Information and Knowledge Management.

Neural response generation via gan with an approximate

Indianapolis, USA, 2016: 649-658

embedding layer//Proceedings of the Empirical Methods

[68] Zens R., Och F.J., Ney H. Phrase-based statistical
machine

translation//German

Conference

on

Ai:

Advances in Artificial Intelligence. Berlin, Heidelberg,
2002: 18-32

in Natural Language Processing. Copenhagen, Denmark,
2017: 617-626
[78] Vinyals O. Le Q.V. A neural conversational model. arXiv
preprint arXiv:1506.05869, 2015

[69] Ritter A., Cherry C., Dolan W.B. Data-driven response

[79] Yao K., Zweig G., Peng B. Attention with intention for a

generation in social media//Proceedings of the Empirical

neural network conversation model. arXiv preprint

Methods in Natural Language Processing. Edinburgh,

arXiv:1510.08565, 2015

UK, 2011: 583-593
[70] Shao L., Gouws S., Britz D., Goldie A., Strope B.,
Kurzweil R. Generating high-quality and informative

[80] Yan R. Zhao D. Smarter response with proactive
suggestion: A new generative neural conversation
paradigm//Proceedings

of

the

International

Joint

计 算 机 学 报

28
Conference

on

Artificial

Intelligence.

Stockholm,

Sweden, 2018: 4525-4531

Pineau J. Building end-to-end dialogue systems using
hierarchical

neural

network

models//Proceedings of the National Conference on
Artificial Intelligence. Phoenix, USA, 2016: 3776-3783
[82] Serban I.V., Sordoni A., Lowe R., Charlin L., Pineau J.,
Courville A.C., Bengio Y. A hierarchical latent variable
encoder-decoder

model

Lee S., Crandall D.J., Batra D. Diverse beam search:
Decoding diverse solutions from neural sequence models.

[81] Serban I.V., Sordoni A., Bengio Y., Courville A.C.,

generative

2019 年

for

generating

arXiv preprint arXiv:1610.02424, 2016
[91] Li J., Monroe W., Jurafsky D. A simple, fast diverse
decoding algorithm for neural generation. arXiv preprint
arXiv:1611.08562, 2016
[92] Yao K., Peng B., Zweig G., Wong K. An attentional
neural conversation model with improved specificity.
arXiv preprint arXiv:1606.01292, 2016

dialogues//

[93] Song Y., Tian Z., Zhao D., Zhang M., Yan R. Diversifying

Proceedings of the National Conference on Artificial

neural conversation model with maximal marginal

Intelligence. San Francisco, USA, 2017: 3295-3301

relevance//Proceedings

[83] Serban I.V., Klinger T., Tesauro G., Talamadupula K.,
Zhou B., Bengio Y., Courville A.C. Multiresolution
recurrent neural networks: An application to dialogue
generation//Proceedings

of

the

the

International

Joint

China, 2017: 169-174
[94] Cao K., Clark S. Latent variable dialogue models and

National

their diversity//Proceedings of the Conference of the

Conference on Artificial Intelligence. Phoenix, USA,

European Chapter of the Association for Computational

2016: 3288-3294

Linguistics. Valencia, Spain, 2017: 182-187

算
计

response

of

Conference on Natural Language Processing. Taipei,

[84] Tian Z., Yan R., Mou L., Song Y., Feng Y., Zhao D. How

[95] Shen X., Su H., Li Y., Li W., Niu S., Zhao Y., Aizawa A.,

to make context more useful? An empirical study on

Long G. A conditional variational framework for dialog

context-aware neural conversational models//Proceedings

generation//Proceedings

of the Meeting of the Association for Computational

Association for Computational Linguistics. Vancouver,

of

the

Meeting

of

the

学
机

Canada, 2017: 504-509

Linguistics. Vancouver, Canada, 2017: 231-236

[85] Chen H., Ren Z., Tang J., Zhao Y.E., Yin D. Hierarchical

[96] Zhou G., Luo P., Cao R., Lin F., Chen B., He Q.

variational memory network for dialogue generation//

Mechanism-aware neural machine for dialogue response

Proceedings of the International World Wide Web

generation//Proceedings of the National Conference on

Conferences. Lyon, France, 2018: 1653-1662

Artificial Intelligence. San Francisco, USA, 2017:

[86] Li J., Luong T., Jurafsky D. A hierarchical neural

3400-3407

报

autoencoder for paragraphs and documents//Proceedings

[97] Zhao T., Zhao R., Eskenazi M. Learning discourse-level

of the International Joint Conference on Natural

diversity for neural dialog models using conditional

Language Processing. Beijing, China, 2015: 1106-1115

variational autoencoders//Proceedings of the Meeting of

[87] Kingma D.P., Welling M. Auto-encoding variational

[88] Li J., Galley M., Brockett C., Gao J., Dolan B. A
diversity-promoting

objective

function

the

Association

for

Computational

Linguistics.

Vancouver, Canada, 2017: 654-664

bayes. arXiv preprint arXiv:1312.6114, 2013

for

neural

[98] Tao C., Gao S., Shang M., Wu W., Zhao D., Yan R. Get
the point of my utterance! Learning towards effective

conversation models//Proceedings of the North American

responses

Chapter of the Association for Computational Linguistics.

Proceedings of the International Joint Conference on

San Diego, USA, 2016: 110-119

Artificial

[89] Qiu M., Li F., Wang S., Gao X., Chen Y., Zhao W., Chen

with

multi-head

Intelligence.

attention

Stockholm,

mechanism//

Sweden,

2018:

4418-4424

H., Huang J., Chu W. Alime chat: A sequence to sequence

[99] Song Y., Yan R., Feng Y., Zhang Y., Dongyan Z., Zhang

and rerank based chatbot engine//Proceedings of the

M. Towards a neural conversation model with diversity

Meeting

net using determinantal point processes//Proceedings of

of

the

Association

for

Computational

Linguistics. Vancouver, Canada, 2017: 498-503
[90] Vijayakumar A.K., Cogswell M., Selvaraju R.R., Sun Q.,

the National Conference on Artificial Intelligence. New
Orleans, USA, 2018: 5932-5939

陈晨等：基于深度学习的开放领域对话系统研究综述
[100] Wu Y., Li Z., Wu W., Zhou M. Response selection with
topic clues for retrieval-based chatbots. Neurocomputing,
2018, 316: 251-261

29

3370-3380
[110] Ghazvininejad M., Brockett C., Chang M., Dolan B.,
Gao J., Yih W., Galley M. A knowledge-grounded neural

[101] Xing C., Wu W., Wu Y., Liu J., Huang Y., Zhou M., Ma

conversation

model//Proceedings

of

the

National

W. Topic aware neural response generation//Proceedings

Conference on Artificial Intelligence, New Orleans,

of the National Conference on Artificial Intelligence. San

USA, 2018: 5110-5117

Francisco, USA, 2017: 3351-3357

[111] Zhou H., Young T., Huang M., Zhao H., Xu J., Zhu X.

[102] Xing C., Wu W., Wu Y., Liu J., Huang Y., Zhou M., Ma

Commonsense knowledge aware conversation generation

W. Topic augmented neural response generation with a

with graph attention//Proceedings of the International

joint

Joint Conference on Artificial Intelligence. Stockholm,

attention

mechanism.

arXiv

preprint

arXiv:1606.08340, 2016

Sweden, 2018: 4623-4629

[103] Choudhary S., Srivastava P., Ungar L.H., Sedoc J.

[112] Zhou H., Huang M., Zhang T., Zhu X., Liu B. Emotional

Domain aware neural dialog system. arXiv preprint

chatting machine: Emotional conversation generation

arXiv:1708.00897, 2017

with internal and external memory//Proceedings of the

[104] Lowe R., Pow N., Serban I., Charlin L., Pineau J.

算
计

Incorporating unstructured textual knowledge sources

National Conference on Artificial Intelligence. New
Orleans, USA, 2018: 730-739

into neural dialogue systems//Proceedings of the Neural

[113] Asghar N., Poupart P., Hoey J., Jiang X., Mou L.

Information Processing Systems Workshop on Machine

Affective neural response generation. Proceedings of the

Learning for Spoken Language Understanding. Montreal,

European

Canada, 2015

Grenoble, France, 2018: 154-166

Conference

on

Information

Retrieval,

[105] Young T., Cambria E., Chaturvedi I., Huang M., Zhou H.,

[114] Zhou X., Wang W.Y. Mojitalk: Generating emotional

Biswas S. Augmenting end-to-end dialogue systems with

responses at scale//Proceedings of the Meeting of the

学
机

commonsense knowledge//Proceedings of the National

Association for Computational Linguistics. Melbourne,

Conference on Artificial Intelligence. New Orleans,

Australia, 2018: 1128-1137

USA, 2018: 4970-4977

[115] Zhang W., Zhu Q., Wang Y., Zhao Y., Liu T. Neural

[106] Yang L., Qiu M., Qu C., Guo J., Zhang Y., Croft W.B.,

personalized

response

generation

as

domain

Huang J., Chen H. Response ranking with deep matching

adaptation//Proceedings of the International World Wide

networks and external knowledge in information-seeking

Web Conferences. Lyon, France, 2018: 1-20

报

conversation systems//Proceedings of the International

[116] Li J., Galley M., Brockett C., Spithourakis G.P., Gao J.,

ACM SIGIR Conference on Research and Development

Dolan B. A persona-based neural conversation model//

in Information Retrieval. Ann Arbor, USA, 2018:

Proceedings of the Meeting of the Association for

245-254

Computational Linguistics. Berlin, Germany, 2016:

[107] Wu Y., Wu W., Li Z. Knowledge enhanced hybrid neural

994-1003

network for text matching//Proceedings of the National

[117] Engonopoulos N., Teichmann C., Koller A. Discovering

Conference on Artificial Intelligence. New Orleans,

user groups for natural language generation. arXiv

USA, 2018: 5586-5593

preprint arXiv:1806.05947, 2018

[108] Zhu W., Mo K., Zhang Y., Zhu Z., Peng X., Yang Q.

[118] Qian Q., Huang M., Zhao H., Xu J., Zhu X. Assigning

Flexible end-to-end dialogue system for knowledge

personality/profile to a chatting machine for coherent

grounded

conversation generation//Proceedings of the International

conversation.

arXiv

preprint

Joint Conference on Artificial Intelligence. Stockholm,

arXiv:1709.04264, 2017
[109] Vougiouklis P., Hare J.S., Simperl E. A neural network
approach for knowledge-driven response generation//
Proceedings
Computational

of

the

International

Linguistics.

Osaka,

Conference
Japan,

on

2016:

Sweden, 2018: 4279-4285
[119] Li X., Mou L., Yan R., Zhang M. Stalematebreaker: A
proactive content-introducing approach to automatic
human-computer

conversation//Proceedings

of

the

计 算 机 学 报

30

International Joint Conference on Artificial Intelligence.
New York, USA, 2016: 2845-2851

and

next

311-318
[129] Galley M., Brockett C., Sordoni A., Ji Y., Auli M., Quirk

[120] Yan R., Zhao D., Weinan E. Joint learning of response
ranking

2019 年

utterance

suggestion

in

C., Mitchell M., Gao J., Dolan B. Deltableu: A
discriminative

metric

generation

tasks

intrinsically

the International ACM SIGIR Conference on Research

International Joint Conference on Natural Language

and Development in Information Retrieval. Tokyo,

Processing. Beijing, China, 2015: 445-450

Semantically

language

of

the

[130] Lin C., Hovy E.H. Automatic evaluation of summaries

[121] Wen T., Gasic M., Mrksic N., Su P., Vandyke D., Young
S.J.

targets//Proceedings

with

human-computer conversation system//Proceedings of

Japan, 2017: 685-694

diverse

for

conditioned

generation

for

lstm-based
spoken

using n-gram co-occurrence statistics//Proceedings of the

natural

North American Chapter of the Association for

dialogue

Computational Linguistics. Edmonton, Canada, 2003:

systems//Proceedings of the Empirical Methods in
Natural Language Processing. Lisbon, Portugal, 2015:

71-78
[131] Lavie A., Agarwal A. Meteor: An automatic metric for mt
evaluation with high levels of correlation with human

1711-1721

judgments//Proceedings of the Workshop on Statistical

loose-structured knowledge into conversation modeling

Machine Translation. Prague, Czech Republic, 2007:

via recall-gate lstm//Proceedings of the International

228-231

算
计

[122] Xu Z., Liu B., Wang B., Sun C., Wang X. Incorporating

Symposium on Neural Networks, Hokkaido, Japan,
2017: 3506-3513

[132] Liu C., Lowe R., Serban I.V., Noseworthy M., Charlin
L., Pineau J. How not to evaluate your dialogue system:

[123] Mou L., Song Y., Yan R., Li G., Zhang L., Jin Z.

An empirical study of unsupervised evaluation metrics

Sequence to backward and forward sequences: A

for dialogue response generation//Proceedings of the

content-introducing approach to generative short-text

Empirical Methods in Natural Language Processing.

of

the

学
机

conversation//Proceedings

International

Conference on Computational Linguistics. Osaka, Japan,

Austin, USA, 2016: 2122-2132

[133] Lowe R., Noseworthy M., Serban I.V., Angelardgontier
N., Bengio Y., Pineau J. Towards an automatic turing

2016: 3349-3358

[124] Yao L., Zhang Y., Feng Y., Zhao D., Yan R. Towards

test:

Learning

to

evaluate

dialogue

responses//Proceedings of the Meeting of the Association

conversation systems//Proceedings of the Empirical

for Computational Linguistics. Vancouver, Canada, 2017:

Methods in Natural Language Processing, Copenhagen,

1116-1126

报

implicit content-introducing for generative short-text

[134] Tao C., Mou L., Yan R., Zhao D. Ruber: An unsupervised

Denmark, 2017: 2190-2199
[125] Asghar N., Poupart P., Jiang X., Li H. Deep active

method for automatic evaluation of open-domain dialog

learning for dialogue generation//Proceedings of the Joint

systems//Proceedings of the National Conference on

Conference on Lexical and Computational Semantics.

Artificial Intelligence. New Orleans, USA, 2018:

Vancouver, Canada, 2017: 78-83

722-729

[126] Li J., Miller A.H., Chopra S., Ranzato M., Weston J.
Dialogue

learning

with

human-in-the-loop.

arXiv

preprint arXiv:1611.09823, 2016
[127] Li J., Miller A.H., Chopra S., Ranzato M., Weston J.
Learning through dialogue interactions by asking
questions. arXiv preprint arXiv: 1612.04936, 2016
[128] Papineni K., Roukos S., Ward T., Zhu W. Bleu: A method

[135] Bowman S.R., Vilnis L., Vinyals O., Dai A.M.,
Jozefowicz R., Bengio S. Generating sentences from a
continuous space//Proceedings of the Conference on
Computational Natural Language Learning. Berlin,
Germany, 2016: 10-21
[136] Kannan A. Vinyals O. Adversarial evaluation of dialogue
models. arXiv preprint arXiv:1701.08198, 2017

for automatic evaluation of machine translation//

[137] Tong X., Fu Z., Shang M., Zhao D., Yan R. One “ruler”

Proceedings of the Meeting of the Association for

for all languages: Multi-lingual dialogue evaluation with

Computational Linguistics. Philadelphia, USA, 2002:

adversarial multi-task learning//Proceedings of the

陈晨等：基于深度学习的开放领域对话系统研究综述
International Joint Conference on Artificial Intelligence.

31

Stockholm, Sweden, 2018: 4432-4438

Chen Chen, born in 1985, Ph.D.,

Zhu Qingqing, born in 1995, Ph.D., Her main research interests

assistant researcher. Her main research

focus on natural language processing.

interests focus on natural language

YAN Rui, born in 1985, Ph.D., assistant professor. His main

processing.

research interests focus on natural language processing.
Liu Junfei, born in 1965, Ph.D., professor. His main research
interests focus on software process.

Background
The human-machine dialogue system enables machines to interact with people through natural language, which is an important task
in artificial intelligence. Because of its commercial value in the fields of virtual assistants and social chatbots, it has been widely
concerned by business and academia. Dialogue systems can be classified as domain-specific and open-domain models.

算
计

Domain-specific dialogue systems accomplish a specific task, while open-domain dialogue systems do not limit the dialogue topic to
a specific domain, and typically do not have a clear dialogue goal.
With the massive human-human conversation utterances available on the web, previous studies have developed data-oriented
approaches in the open domain, which can be roughly categorized into two groups: retrieval systems and generative systems. It is
intuitive to build a retrieval based conversational system as information retrieval techniques are developing fast since 2003. Also,
recent studies use generation-based methods by training a sequence-to-sequence neural network (Seq2Seq) to build open-domain
dialogue systems. These models directly synthesize new sentences as responses according to the previous queries. In this survey, we

学
机

will summarize the problem formulation for chatbots, and give an overview of state-of-the-art methods for open domain dialogue
systems from several aspects.

报

